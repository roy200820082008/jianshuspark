[INFO] [2018-10-22 12:14:16][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-22 12:14:17][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@2b2948e2: startup date [Mon Oct 22 12:14:17 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 12:14:17][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-22 12:14:17][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-22 12:14:17][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-22 12:14:17][org.apache.spark.SparkContext]Running Spark version 1.6.0
[WARN] [2018-10-22 12:14:18][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] [2018-10-22 12:14:18][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-22 12:14:18][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-22 12:14:18][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(rym2017); users with modify permissions: Set(rym2017)
[INFO] [2018-10-22 12:14:19][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 3671.
[INFO] [2018-10-22 12:14:19][akka.event.slf4j.Slf4jLogger]Slf4jLogger started
[INFO] [2018-10-22 12:14:19][Remoting]Starting remoting
[INFO] [2018-10-22 12:14:20][Remoting]Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.1:3685]
[INFO] [2018-10-22 12:14:20][org.apache.spark.util.Utils]Successfully started service 'sparkDriverActorSystem' on port 3685.
[INFO] [2018-10-22 12:14:20][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-22 12:14:20][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-22 12:14:20][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-aee901a0-8c3d-4abf-aec4-d4e5e1579758
[INFO] [2018-10-22 12:14:20][org.apache.spark.storage.MemoryStore]MemoryStore started with capacity 3.8 GB
[INFO] [2018-10-22 12:14:20][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-22 12:14:20][org.spark-project.jetty.server.Server]jetty-8.y.z-SNAPSHOT
[INFO] [2018-10-22 12:14:20][org.spark-project.jetty.server.AbstractConnector]Started SelectChannelConnector@0.0.0.0:4040
[INFO] [2018-10-22 12:14:20][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-22 12:14:20][org.apache.spark.ui.SparkUI]Started SparkUI at http://192.168.68.1:4040
[INFO] [2018-10-22 12:14:20][org.apache.spark.executor.Executor]Starting executor ID driver on host localhost
[INFO] [2018-10-22 12:14:20][org.apache.spark.util.Utils]Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 3695.
[INFO] [2018-10-22 12:14:20][org.apache.spark.network.netty.NettyBlockTransferService]Server created on 3695
[INFO] [2018-10-22 12:14:20][org.apache.spark.storage.BlockManagerMaster]Trying to register BlockManager
[INFO] [2018-10-22 12:14:20][org.apache.spark.storage.BlockManagerMasterEndpoint]Registering block manager localhost:3695 with 3.8 GB RAM, BlockManagerId(driver, localhost, 3695)
[INFO] [2018-10-22 12:14:20][org.apache.spark.storage.BlockManagerMaster]Registered BlockManager
[INFO] [2018-10-22 12:14:21][com.harleycorp.testmybatis.TestMyBatis][{"age":23,"id":1,"password":"000000","userName":"lisa"},{"age":22,"id":2,"password":"123456","userName":"jack"}]
[INFO] [2018-10-22 12:14:21][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@2b2948e2: startup date [Mon Oct 22 12:14:17 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 12:14:21][org.apache.spark.SparkContext]Invoking stop() from shutdown hook
[INFO] [2018-10-22 12:14:21][org.apache.spark.SparkContext]SparkContext already stopped.
[INFO] [2018-10-22 12:14:21][org.apache.spark.storage.DiskBlockManager]Shutdown hook called
[INFO] [2018-10-22 12:14:21][org.apache.spark.util.ShutdownHookManager]Shutdown hook called
[INFO] [2018-10-22 12:14:21][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-10178c4d-ae09-4c90-8a40-3acd70112248
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/static/sql,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/execution/json,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/execution,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/json,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO] [2018-10-22 12:14:21][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO] [2018-10-22 12:14:21][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-10178c4d-ae09-4c90-8a40-3acd70112248\userFiles-5ebc738e-e52f-4945-986b-b70f949e318a
[INFO] [2018-10-22 12:14:21][org.apache.spark.ui.SparkUI]Stopped Spark web UI at http://192.168.68.1:4040
[INFO] [2018-10-22 12:14:21][org.apache.spark.MapOutputTrackerMasterEndpoint]MapOutputTrackerMasterEndpoint stopped!
[INFO] [2018-10-22 12:14:21][org.apache.spark.storage.MemoryStore]MemoryStore cleared
[INFO] [2018-10-22 12:14:21][org.apache.spark.storage.BlockManager]BlockManager stopped
[INFO] [2018-10-22 12:14:21][org.apache.spark.storage.BlockManagerMaster]BlockManagerMaster stopped
[INFO] [2018-10-22 12:14:21][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint]OutputCommitCoordinator stopped!
[INFO] [2018-10-22 12:14:21][org.apache.spark.SparkContext]Successfully stopped SparkContext
[INFO] [2018-10-22 12:15:41][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-22 12:15:41][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@2b2948e2: startup date [Mon Oct 22 12:15:41 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 12:15:41][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-22 12:15:41][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-22 12:15:41][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-22 12:15:42][org.apache.spark.SparkContext]Running Spark version 1.6.0
[WARN] [2018-10-22 12:15:42][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] [2018-10-22 12:15:43][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-22 12:15:43][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-22 12:15:43][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(rym2017); users with modify permissions: Set(rym2017)
[INFO] [2018-10-22 12:15:43][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 3802.
[INFO] [2018-10-22 12:15:44][akka.event.slf4j.Slf4jLogger]Slf4jLogger started
[INFO] [2018-10-22 12:15:44][Remoting]Starting remoting
[INFO] [2018-10-22 12:15:44][Remoting]Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.1:3815]
[INFO] [2018-10-22 12:15:44][org.apache.spark.util.Utils]Successfully started service 'sparkDriverActorSystem' on port 3815.
[INFO] [2018-10-22 12:15:44][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-22 12:15:44][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-22 12:15:44][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-1c901a73-c0f5-447f-a9fb-a7c939b0d85f
[INFO] [2018-10-22 12:15:44][org.apache.spark.storage.MemoryStore]MemoryStore started with capacity 3.8 GB
[INFO] [2018-10-22 12:15:44][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-22 12:15:45][org.spark-project.jetty.server.Server]jetty-8.y.z-SNAPSHOT
[INFO] [2018-10-22 12:15:45][org.spark-project.jetty.server.AbstractConnector]Started SelectChannelConnector@0.0.0.0:4040
[INFO] [2018-10-22 12:15:45][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-22 12:15:45][org.apache.spark.ui.SparkUI]Started SparkUI at http://192.168.68.1:4040
[INFO] [2018-10-22 12:15:45][org.apache.spark.executor.Executor]Starting executor ID driver on host localhost
[INFO] [2018-10-22 12:15:45][org.apache.spark.util.Utils]Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 3825.
[INFO] [2018-10-22 12:15:45][org.apache.spark.network.netty.NettyBlockTransferService]Server created on 3825
[INFO] [2018-10-22 12:15:45][org.apache.spark.storage.BlockManagerMaster]Trying to register BlockManager
[INFO] [2018-10-22 12:15:45][org.apache.spark.storage.BlockManagerMasterEndpoint]Registering block manager localhost:3825 with 3.8 GB RAM, BlockManagerId(driver, localhost, 3825)
[INFO] [2018-10-22 12:15:45][org.apache.spark.storage.BlockManagerMaster]Registered BlockManager
[INFO] [2018-10-22 12:15:45][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this url:jdbc:mysql://192.168.68.244:3306/test?useUnicode=true&characterEncoding=UTF-8
[INFO] [2018-10-22 12:15:45][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this table:testtable
[INFO] [2018-10-22 12:15:45][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this master:local
[INFO] [2018-10-22 12:15:45][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this username:root
[INFO] [2018-10-22 12:15:45][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this password:mysql
[INFO] [2018-10-22 12:15:46][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@2b2948e2: startup date [Mon Oct 22 12:15:41 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 12:15:46][org.apache.spark.SparkContext]Invoking stop() from shutdown hook
[INFO] [2018-10-22 12:15:46][org.apache.spark.SparkContext]SparkContext already stopped.
[INFO] [2018-10-22 12:15:46][org.apache.spark.storage.DiskBlockManager]Shutdown hook called
[INFO] [2018-10-22 12:15:46][org.apache.spark.util.ShutdownHookManager]Shutdown hook called
[INFO] [2018-10-22 12:15:46][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-a5cb1e8e-58bf-4908-8ee9-a2d1bed71250\userFiles-f45da3b2-0f3c-46fd-9e0f-134d3bf2a649
[INFO] [2018-10-22 12:15:46][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-a5cb1e8e-58bf-4908-8ee9-a2d1bed71250
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/static/sql,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/execution/json,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/execution,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/json,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO] [2018-10-22 12:15:46][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO] [2018-10-22 12:15:46][org.apache.spark.ui.SparkUI]Stopped Spark web UI at http://192.168.68.1:4040
[INFO] [2018-10-22 12:15:46][org.apache.spark.MapOutputTrackerMasterEndpoint]MapOutputTrackerMasterEndpoint stopped!
[INFO] [2018-10-22 12:15:46][org.apache.spark.storage.MemoryStore]MemoryStore cleared
[INFO] [2018-10-22 12:15:46][org.apache.spark.storage.BlockManager]BlockManager stopped
[INFO] [2018-10-22 12:15:46][org.apache.spark.storage.BlockManagerMaster]BlockManagerMaster stopped
[INFO] [2018-10-22 12:15:46][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint]OutputCommitCoordinator stopped!
[INFO] [2018-10-22 12:15:46][org.apache.spark.SparkContext]Successfully stopped SparkContext
[INFO] [2018-10-22 12:18:33][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-22 12:18:33][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@2b2948e2: startup date [Mon Oct 22 12:18:33 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 12:18:33][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-22 12:18:33][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-22 12:18:33][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-22 12:18:34][org.apache.spark.SparkContext]Running Spark version 1.6.0
[WARN] [2018-10-22 12:18:34][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] [2018-10-22 12:18:34][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-22 12:18:34][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-22 12:18:34][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(rym2017); users with modify permissions: Set(rym2017)
[INFO] [2018-10-22 12:18:35][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 3998.
[INFO] [2018-10-22 12:18:36][akka.event.slf4j.Slf4jLogger]Slf4jLogger started
[INFO] [2018-10-22 12:18:36][Remoting]Starting remoting
[INFO] [2018-10-22 12:18:36][Remoting]Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.1:4014]
[INFO] [2018-10-22 12:18:36][org.apache.spark.util.Utils]Successfully started service 'sparkDriverActorSystem' on port 4014.
[INFO] [2018-10-22 12:18:36][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-22 12:18:36][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-22 12:18:36][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-734a8cd4-3097-4d81-8963-352f4dc81d5b
[INFO] [2018-10-22 12:18:36][org.apache.spark.storage.MemoryStore]MemoryStore started with capacity 3.8 GB
[INFO] [2018-10-22 12:18:36][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-22 12:18:36][org.spark-project.jetty.server.Server]jetty-8.y.z-SNAPSHOT
[INFO] [2018-10-22 12:18:36][org.spark-project.jetty.server.AbstractConnector]Started SelectChannelConnector@0.0.0.0:4040
[INFO] [2018-10-22 12:18:36][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-22 12:18:36][org.apache.spark.ui.SparkUI]Started SparkUI at http://192.168.68.1:4040
[INFO] [2018-10-22 12:18:36][org.apache.spark.executor.Executor]Starting executor ID driver on host localhost
[INFO] [2018-10-22 12:18:36][org.apache.spark.util.Utils]Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 4024.
[INFO] [2018-10-22 12:18:36][org.apache.spark.network.netty.NettyBlockTransferService]Server created on 4024
[INFO] [2018-10-22 12:18:36][org.apache.spark.storage.BlockManagerMaster]Trying to register BlockManager
[INFO] [2018-10-22 12:18:36][org.apache.spark.storage.BlockManagerMasterEndpoint]Registering block manager localhost:4024 with 3.8 GB RAM, BlockManagerId(driver, localhost, 4024)
[INFO] [2018-10-22 12:18:36][org.apache.spark.storage.BlockManagerMaster]Registered BlockManager
[INFO] [2018-10-22 12:18:37][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this url:jdbc:mysql://192.168.68.244:3306/test?useUnicode=true&characterEncoding=UTF-8
[INFO] [2018-10-22 12:18:37][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this table:testtable
[INFO] [2018-10-22 12:18:37][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this master:local
[INFO] [2018-10-22 12:18:37][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this username:root
[INFO] [2018-10-22 12:18:37][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this password:mysql
[INFO] [2018-10-22 12:18:37][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@2b2948e2: startup date [Mon Oct 22 12:18:33 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 12:18:37][org.apache.spark.SparkContext]Invoking stop() from shutdown hook
[INFO] [2018-10-22 12:18:37][org.apache.spark.SparkContext]SparkContext already stopped.
[INFO] [2018-10-22 12:18:37][org.apache.spark.storage.DiskBlockManager]Shutdown hook called
[INFO] [2018-10-22 12:18:37][org.apache.spark.util.ShutdownHookManager]Shutdown hook called
[INFO] [2018-10-22 12:18:37][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-40aeb621-933f-48e2-8641-810b3fa3eff4\userFiles-3a81d634-9247-4e3f-aa97-d68cdabb81b5
[INFO] [2018-10-22 12:18:37][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-40aeb621-933f-48e2-8641-810b3fa3eff4
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/static/sql,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/execution/json,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/execution,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/json,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO] [2018-10-22 12:18:37][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO] [2018-10-22 12:18:37][org.apache.spark.ui.SparkUI]Stopped Spark web UI at http://192.168.68.1:4040
[INFO] [2018-10-22 12:18:37][org.apache.spark.MapOutputTrackerMasterEndpoint]MapOutputTrackerMasterEndpoint stopped!
[INFO] [2018-10-22 12:18:37][org.apache.spark.storage.MemoryStore]MemoryStore cleared
[INFO] [2018-10-22 12:18:37][org.apache.spark.storage.BlockManager]BlockManager stopped
[INFO] [2018-10-22 12:18:37][org.apache.spark.storage.BlockManagerMaster]BlockManagerMaster stopped
[INFO] [2018-10-22 12:18:37][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint]OutputCommitCoordinator stopped!
[INFO] [2018-10-22 12:18:37][org.apache.spark.SparkContext]Successfully stopped SparkContext
[INFO] [2018-10-22 12:20:29][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-22 12:20:29][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@2b2948e2: startup date [Mon Oct 22 12:20:29 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 12:20:29][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-22 12:20:29][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-22 12:20:29][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-22 12:20:30][org.apache.spark.SparkContext]Running Spark version 1.6.0
[WARN] [2018-10-22 12:20:31][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] [2018-10-22 12:20:31][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-22 12:20:31][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-22 12:20:31][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(rym2017); users with modify permissions: Set(rym2017)
[INFO] [2018-10-22 12:20:32][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 4154.
[INFO] [2018-10-22 12:20:32][akka.event.slf4j.Slf4jLogger]Slf4jLogger started
[INFO] [2018-10-22 12:20:32][Remoting]Starting remoting
[INFO] [2018-10-22 12:20:32][Remoting]Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.1:4167]
[INFO] [2018-10-22 12:20:32][org.apache.spark.util.Utils]Successfully started service 'sparkDriverActorSystem' on port 4167.
[INFO] [2018-10-22 12:20:32][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-22 12:20:32][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-22 12:20:32][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-d1f9e015-85e4-418f-bca8-b90ba3c6b469
[INFO] [2018-10-22 12:20:32][org.apache.spark.storage.MemoryStore]MemoryStore started with capacity 3.8 GB
[INFO] [2018-10-22 12:20:32][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-22 12:20:33][org.spark-project.jetty.server.Server]jetty-8.y.z-SNAPSHOT
[INFO] [2018-10-22 12:20:33][org.spark-project.jetty.server.AbstractConnector]Started SelectChannelConnector@0.0.0.0:4040
[INFO] [2018-10-22 12:20:33][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-22 12:20:33][org.apache.spark.ui.SparkUI]Started SparkUI at http://192.168.68.1:4040
[INFO] [2018-10-22 12:20:33][org.apache.spark.executor.Executor]Starting executor ID driver on host localhost
[INFO] [2018-10-22 12:20:33][org.apache.spark.util.Utils]Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 4176.
[INFO] [2018-10-22 12:20:33][org.apache.spark.network.netty.NettyBlockTransferService]Server created on 4176
[INFO] [2018-10-22 12:20:33][org.apache.spark.storage.BlockManagerMaster]Trying to register BlockManager
[INFO] [2018-10-22 12:20:33][org.apache.spark.storage.BlockManagerMasterEndpoint]Registering block manager localhost:4176 with 3.8 GB RAM, BlockManagerId(driver, localhost, 4176)
[INFO] [2018-10-22 12:20:33][org.apache.spark.storage.BlockManagerMaster]Registered BlockManager
[INFO] [2018-10-22 12:20:34][com.harleycorp.testmybatis.TestMyBatis][{"age":23,"id":1,"password":"000000","userName":"lisa"},{"age":22,"id":2,"password":"123456","userName":"jack"}]
[INFO] [2018-10-22 12:20:34][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@2b2948e2: startup date [Mon Oct 22 12:20:29 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 12:20:34][org.apache.spark.SparkContext]Invoking stop() from shutdown hook
[INFO] [2018-10-22 12:20:34][org.apache.spark.SparkContext]SparkContext already stopped.
[INFO] [2018-10-22 12:20:34][org.apache.spark.storage.DiskBlockManager]Shutdown hook called
[INFO] [2018-10-22 12:20:34][org.apache.spark.util.ShutdownHookManager]Shutdown hook called
[INFO] [2018-10-22 12:20:34][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-390ce3cf-4668-4489-b6d7-96d9ad88ba70\userFiles-cf81d1c1-5dbe-4daa-9046-d20dbedbb24a
[INFO] [2018-10-22 12:20:34][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-390ce3cf-4668-4489-b6d7-96d9ad88ba70
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/static/sql,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/execution/json,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/execution,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/json,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO] [2018-10-22 12:20:34][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO] [2018-10-22 12:20:34][org.apache.spark.ui.SparkUI]Stopped Spark web UI at http://192.168.68.1:4040
[INFO] [2018-10-22 12:20:34][org.apache.spark.MapOutputTrackerMasterEndpoint]MapOutputTrackerMasterEndpoint stopped!
[INFO] [2018-10-22 12:20:34][org.apache.spark.storage.MemoryStore]MemoryStore cleared
[INFO] [2018-10-22 12:20:34][org.apache.spark.storage.BlockManager]BlockManager stopped
[INFO] [2018-10-22 12:20:34][org.apache.spark.storage.BlockManagerMaster]BlockManagerMaster stopped
[INFO] [2018-10-22 12:20:34][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint]OutputCommitCoordinator stopped!
[INFO] [2018-10-22 12:20:34][org.apache.spark.SparkContext]Successfully stopped SparkContext
[INFO] [2018-10-22 12:21:52][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-22 12:21:52][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@5a63f509: startup date [Mon Oct 22 12:21:52 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 12:21:52][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-22 12:21:52][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-22 12:21:52][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-22 12:21:53][org.apache.spark.SparkContext]Running Spark version 1.6.0
[WARN] [2018-10-22 12:21:54][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] [2018-10-22 12:21:54][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-22 12:21:54][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-22 12:21:54][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(rym2017); users with modify permissions: Set(rym2017)
[INFO] [2018-10-22 12:21:55][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 4280.
[INFO] [2018-10-22 12:21:55][akka.event.slf4j.Slf4jLogger]Slf4jLogger started
[INFO] [2018-10-22 12:21:55][Remoting]Starting remoting
[INFO] [2018-10-22 12:21:56][Remoting]Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.1:4293]
[INFO] [2018-10-22 12:21:56][org.apache.spark.util.Utils]Successfully started service 'sparkDriverActorSystem' on port 4293.
[INFO] [2018-10-22 12:21:56][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-22 12:21:56][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-22 12:21:56][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-18646b2f-4fb4-4616-b1f9-c1a4e3c5d025
[INFO] [2018-10-22 12:21:56][org.apache.spark.storage.MemoryStore]MemoryStore started with capacity 3.8 GB
[INFO] [2018-10-22 12:21:56][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-22 12:21:56][org.spark-project.jetty.server.Server]jetty-8.y.z-SNAPSHOT
[INFO] [2018-10-22 12:21:56][org.spark-project.jetty.server.AbstractConnector]Started SelectChannelConnector@0.0.0.0:4040
[INFO] [2018-10-22 12:21:56][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-22 12:21:56][org.apache.spark.ui.SparkUI]Started SparkUI at http://192.168.68.1:4040
[INFO] [2018-10-22 12:21:56][org.apache.spark.executor.Executor]Starting executor ID driver on host localhost
[INFO] [2018-10-22 12:21:56][org.apache.spark.util.Utils]Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 4303.
[INFO] [2018-10-22 12:21:56][org.apache.spark.network.netty.NettyBlockTransferService]Server created on 4303
[INFO] [2018-10-22 12:21:56][org.apache.spark.storage.BlockManagerMaster]Trying to register BlockManager
[INFO] [2018-10-22 12:21:56][org.apache.spark.storage.BlockManagerMasterEndpoint]Registering block manager localhost:4303 with 3.8 GB RAM, BlockManagerId(driver, localhost, 4303)
[INFO] [2018-10-22 12:21:56][org.apache.spark.storage.BlockManagerMaster]Registered BlockManager
[INFO] [2018-10-22 12:22:05][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this url:jdbc:mysql://192.168.68.244:3306/test?useUnicode=true&characterEncoding=UTF-8
[INFO] [2018-10-22 12:22:11][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this table:testtable
[INFO] [2018-10-22 12:22:14][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this master:local
[INFO] [2018-10-22 12:22:22][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this username:root
[INFO] [2018-10-22 12:22:25][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this password:mysql
[INFO] [2018-10-22 12:24:06][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-22 12:24:06][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@2b2948e2: startup date [Mon Oct 22 12:24:06 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 12:24:06][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-22 12:24:06][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-22 12:24:06][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-22 12:24:07][org.apache.spark.SparkContext]Running Spark version 1.6.0
[WARN] [2018-10-22 12:24:07][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] [2018-10-22 12:24:07][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-22 12:24:07][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-22 12:24:07][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(rym2017); users with modify permissions: Set(rym2017)
[INFO] [2018-10-22 12:24:08][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 4451.
[INFO] [2018-10-22 12:24:09][akka.event.slf4j.Slf4jLogger]Slf4jLogger started
[INFO] [2018-10-22 12:24:09][Remoting]Starting remoting
[INFO] [2018-10-22 12:24:09][Remoting]Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.1:4464]
[INFO] [2018-10-22 12:24:09][org.apache.spark.util.Utils]Successfully started service 'sparkDriverActorSystem' on port 4464.
[INFO] [2018-10-22 12:24:09][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-22 12:24:09][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-22 12:24:09][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-5878588b-21f8-4684-8395-6638c13a0466
[INFO] [2018-10-22 12:24:09][org.apache.spark.storage.MemoryStore]MemoryStore started with capacity 3.8 GB
[INFO] [2018-10-22 12:24:09][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-22 12:24:09][org.spark-project.jetty.server.Server]jetty-8.y.z-SNAPSHOT
[INFO] [2018-10-22 12:24:09][org.spark-project.jetty.server.AbstractConnector]Started SelectChannelConnector@0.0.0.0:4040
[INFO] [2018-10-22 12:24:09][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-22 12:24:09][org.apache.spark.ui.SparkUI]Started SparkUI at http://192.168.68.1:4040
[INFO] [2018-10-22 12:24:09][org.apache.spark.executor.Executor]Starting executor ID driver on host localhost
[INFO] [2018-10-22 12:24:09][org.apache.spark.util.Utils]Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 4473.
[INFO] [2018-10-22 12:24:09][org.apache.spark.network.netty.NettyBlockTransferService]Server created on 4473
[INFO] [2018-10-22 12:24:09][org.apache.spark.storage.BlockManagerMaster]Trying to register BlockManager
[INFO] [2018-10-22 12:24:09][org.apache.spark.storage.BlockManagerMasterEndpoint]Registering block manager localhost:4473 with 3.8 GB RAM, BlockManagerId(driver, localhost, 4473)
[INFO] [2018-10-22 12:24:09][org.apache.spark.storage.BlockManagerMaster]Registered BlockManager
[INFO] [2018-10-22 12:24:10][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this url:jdbc:mysql://192.168.68.244:3306/test?useUnicode=true&characterEncoding=UTF-8
[INFO] [2018-10-22 12:24:10][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this table:testtable
[INFO] [2018-10-22 12:24:10][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this master:local
[INFO] [2018-10-22 12:24:10][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this username:root
[INFO] [2018-10-22 12:24:10][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this password:root
[INFO] [2018-10-22 12:24:12][org.apache.spark.SparkContext]Starting job: collect at SparkUpperServiceImpl.java:62
[INFO] [2018-10-22 12:24:13][org.apache.spark.scheduler.DAGScheduler]Got job 0 (collect at SparkUpperServiceImpl.java:62) with 1 output partitions
[INFO] [2018-10-22 12:24:13][org.apache.spark.scheduler.DAGScheduler]Final stage: ResultStage 0 (collect at SparkUpperServiceImpl.java:62)
[INFO] [2018-10-22 12:24:13][org.apache.spark.scheduler.DAGScheduler]Parents of final stage: List()
[INFO] [2018-10-22 12:24:13][org.apache.spark.scheduler.DAGScheduler]Missing parents: List()
[INFO] [2018-10-22 12:24:13][org.apache.spark.scheduler.DAGScheduler]Submitting ResultStage 0 (MapPartitionsRDD[1] at javaRDD at SparkUpperServiceImpl.java:62), which has no missing parents
[INFO] [2018-10-22 12:24:13][org.apache.spark.storage.MemoryStore]Block broadcast_0 stored as values in memory (estimated size 5.0 KB, free 5.0 KB)
[INFO] [2018-10-22 12:24:13][org.apache.spark.storage.MemoryStore]Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.4 KB, free 7.5 KB)
[INFO] [2018-10-22 12:24:13][org.apache.spark.storage.BlockManagerInfo]Added broadcast_0_piece0 in memory on localhost:4473 (size: 2.4 KB, free: 3.8 GB)
[INFO] [2018-10-22 12:24:13][org.apache.spark.SparkContext]Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO] [2018-10-22 12:24:13][org.apache.spark.scheduler.DAGScheduler]Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at javaRDD at SparkUpperServiceImpl.java:62)
[INFO] [2018-10-22 12:24:13][org.apache.spark.scheduler.TaskSchedulerImpl]Adding task set 0.0 with 1 tasks
[INFO] [2018-10-22 12:24:13][org.apache.spark.scheduler.TaskSetManager]Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 1841 bytes)
[INFO] [2018-10-22 12:24:13][org.apache.spark.executor.Executor]Running task 0.0 in stage 0.0 (TID 0)
[INFO] [2018-10-22 12:24:13][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD]closed connection
[INFO] [2018-10-22 12:24:13][org.apache.spark.executor.Executor]Finished task 0.0 in stage 0.0 (TID 0). 2363 bytes result sent to driver
[INFO] [2018-10-22 12:24:13][org.apache.spark.scheduler.TaskSetManager]Finished task 0.0 in stage 0.0 (TID 0) in 105 ms on localhost (1/1)
[INFO] [2018-10-22 12:24:13][org.apache.spark.scheduler.TaskSchedulerImpl]Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] [2018-10-22 12:24:13][org.apache.spark.scheduler.DAGScheduler]ResultStage 0 (collect at SparkUpperServiceImpl.java:62) finished in 0.118 s
[INFO] [2018-10-22 12:24:13][org.apache.spark.scheduler.DAGScheduler]Job 0 finished: collect at SparkUpperServiceImpl.java:62, took 0.295072 s
[INFO] [2018-10-22 12:24:13][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@2b2948e2: startup date [Mon Oct 22 12:24:06 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 12:24:13][org.apache.spark.SparkContext]Invoking stop() from shutdown hook
[INFO] [2018-10-22 12:24:13][org.apache.spark.SparkContext]SparkContext already stopped.
[INFO] [2018-10-22 12:24:13][org.apache.spark.storage.DiskBlockManager]Shutdown hook called
[INFO] [2018-10-22 12:24:13][org.apache.spark.util.ShutdownHookManager]Shutdown hook called
[INFO] [2018-10-22 12:24:13][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-894e28a8-698c-4488-91bc-88e210e5d9f1\userFiles-e5c0ba22-0fab-46f0-8d8a-8ca74450df97
[INFO] [2018-10-22 12:24:13][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-894e28a8-698c-4488-91bc-88e210e5d9f1
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/static/sql,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/execution/json,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/execution,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/json,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO] [2018-10-22 12:24:13][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO] [2018-10-22 12:24:13][org.apache.spark.ui.SparkUI]Stopped Spark web UI at http://192.168.68.1:4040
[INFO] [2018-10-22 12:24:13][org.apache.spark.MapOutputTrackerMasterEndpoint]MapOutputTrackerMasterEndpoint stopped!
[INFO] [2018-10-22 12:24:13][org.apache.spark.storage.MemoryStore]MemoryStore cleared
[INFO] [2018-10-22 12:24:13][org.apache.spark.storage.BlockManager]BlockManager stopped
[INFO] [2018-10-22 12:24:13][org.apache.spark.storage.BlockManagerMaster]BlockManagerMaster stopped
[INFO] [2018-10-22 12:24:13][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint]OutputCommitCoordinator stopped!
[INFO] [2018-10-22 12:24:13][org.apache.spark.SparkContext]Successfully stopped SparkContext
[INFO] [2018-10-22 12:25:37][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-22 12:25:37][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@2b2948e2: startup date [Mon Oct 22 12:25:37 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 12:25:37][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-22 12:25:37][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-22 12:25:37][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-22 12:25:38][org.apache.spark.SparkContext]Running Spark version 1.6.0
[WARN] [2018-10-22 12:25:38][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] [2018-10-22 12:25:39][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-22 12:25:39][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-22 12:25:39][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(rym2017); users with modify permissions: Set(rym2017)
[INFO] [2018-10-22 12:25:39][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 4585.
[INFO] [2018-10-22 12:25:40][akka.event.slf4j.Slf4jLogger]Slf4jLogger started
[INFO] [2018-10-22 12:25:40][Remoting]Starting remoting
[INFO] [2018-10-22 12:25:40][Remoting]Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.1:4599]
[INFO] [2018-10-22 12:25:40][org.apache.spark.util.Utils]Successfully started service 'sparkDriverActorSystem' on port 4599.
[INFO] [2018-10-22 12:25:40][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-22 12:25:40][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-22 12:25:40][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-68baf23e-d90c-419a-8aa0-81240854c6fa
[INFO] [2018-10-22 12:25:40][org.apache.spark.storage.MemoryStore]MemoryStore started with capacity 3.8 GB
[INFO] [2018-10-22 12:25:40][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-22 12:25:41][org.spark-project.jetty.server.Server]jetty-8.y.z-SNAPSHOT
[INFO] [2018-10-22 12:25:41][org.spark-project.jetty.server.AbstractConnector]Started SelectChannelConnector@0.0.0.0:4040
[INFO] [2018-10-22 12:25:41][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-22 12:25:41][org.apache.spark.ui.SparkUI]Started SparkUI at http://192.168.68.1:4040
[INFO] [2018-10-22 12:25:41][org.apache.spark.executor.Executor]Starting executor ID driver on host localhost
[INFO] [2018-10-22 12:25:41][org.apache.spark.util.Utils]Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 4608.
[INFO] [2018-10-22 12:25:41][org.apache.spark.network.netty.NettyBlockTransferService]Server created on 4608
[INFO] [2018-10-22 12:25:41][org.apache.spark.storage.BlockManagerMaster]Trying to register BlockManager
[INFO] [2018-10-22 12:25:41][org.apache.spark.storage.BlockManagerMasterEndpoint]Registering block manager localhost:4608 with 3.8 GB RAM, BlockManagerId(driver, localhost, 4608)
[INFO] [2018-10-22 12:25:41][org.apache.spark.storage.BlockManagerMaster]Registered BlockManager
[INFO] [2018-10-22 12:25:41][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this url:jdbc:mysql://192.168.68.244:3306/test?useUnicode=true&characterEncoding=UTF-8
[INFO] [2018-10-22 12:25:41][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this table:testtable
[INFO] [2018-10-22 12:25:41][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this master:local
[INFO] [2018-10-22 12:25:41][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this username:root
[INFO] [2018-10-22 12:25:41][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this password:root
[INFO] [2018-10-22 12:25:44][org.apache.spark.SparkContext]Starting job: show at SparkUpperServiceImpl.java:63
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.DAGScheduler]Got job 0 (show at SparkUpperServiceImpl.java:63) with 1 output partitions
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.DAGScheduler]Final stage: ResultStage 0 (show at SparkUpperServiceImpl.java:63)
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.DAGScheduler]Parents of final stage: List()
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.DAGScheduler]Missing parents: List()
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.DAGScheduler]Submitting ResultStage 0 (MapPartitionsRDD[1] at show at SparkUpperServiceImpl.java:63), which has no missing parents
[INFO] [2018-10-22 12:25:44][org.apache.spark.storage.MemoryStore]Block broadcast_0 stored as values in memory (estimated size 4.8 KB, free 4.8 KB)
[INFO] [2018-10-22 12:25:44][org.apache.spark.storage.MemoryStore]Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.3 KB, free 7.1 KB)
[INFO] [2018-10-22 12:25:44][org.apache.spark.storage.BlockManagerInfo]Added broadcast_0_piece0 in memory on localhost:4608 (size: 2.3 KB, free: 3.8 GB)
[INFO] [2018-10-22 12:25:44][org.apache.spark.SparkContext]Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.DAGScheduler]Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at show at SparkUpperServiceImpl.java:63)
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.TaskSchedulerImpl]Adding task set 0.0 with 1 tasks
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.TaskSetManager]Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 1841 bytes)
[INFO] [2018-10-22 12:25:44][org.apache.spark.executor.Executor]Running task 0.0 in stage 0.0 (TID 0)
[INFO] [2018-10-22 12:25:44][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD]closed connection
[INFO] [2018-10-22 12:25:44][org.apache.spark.executor.Executor]Finished task 0.0 in stage 0.0 (TID 0). 1572 bytes result sent to driver
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.TaskSetManager]Finished task 0.0 in stage 0.0 (TID 0) in 105 ms on localhost (1/1)
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.TaskSchedulerImpl]Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.DAGScheduler]ResultStage 0 (show at SparkUpperServiceImpl.java:63) finished in 0.120 s
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.DAGScheduler]Job 0 finished: show at SparkUpperServiceImpl.java:63, took 0.349699 s
[INFO] [2018-10-22 12:25:44][org.apache.spark.SparkContext]Starting job: collect at SparkUpperServiceImpl.java:64
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.DAGScheduler]Got job 1 (collect at SparkUpperServiceImpl.java:64) with 1 output partitions
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.DAGScheduler]Final stage: ResultStage 1 (collect at SparkUpperServiceImpl.java:64)
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.DAGScheduler]Parents of final stage: List()
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.DAGScheduler]Missing parents: List()
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.DAGScheduler]Submitting ResultStage 1 (MapPartitionsRDD[3] at javaRDD at SparkUpperServiceImpl.java:64), which has no missing parents
[INFO] [2018-10-22 12:25:44][org.apache.spark.storage.MemoryStore]Block broadcast_1 stored as values in memory (estimated size 5.0 KB, free 12.1 KB)
[INFO] [2018-10-22 12:25:44][org.apache.spark.storage.MemoryStore]Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.4 KB, free 14.5 KB)
[INFO] [2018-10-22 12:25:44][org.apache.spark.storage.BlockManagerInfo]Added broadcast_1_piece0 in memory on localhost:4608 (size: 2.4 KB, free: 3.8 GB)
[INFO] [2018-10-22 12:25:44][org.apache.spark.SparkContext]Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.DAGScheduler]Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at javaRDD at SparkUpperServiceImpl.java:64)
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.TaskSchedulerImpl]Adding task set 1.0 with 1 tasks
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.TaskSetManager]Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,PROCESS_LOCAL, 1841 bytes)
[INFO] [2018-10-22 12:25:44][org.apache.spark.executor.Executor]Running task 0.0 in stage 1.0 (TID 1)
[INFO] [2018-10-22 12:25:44][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD]closed connection
[INFO] [2018-10-22 12:25:44][org.apache.spark.executor.Executor]Finished task 0.0 in stage 1.0 (TID 1). 2363 bytes result sent to driver
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.TaskSetManager]Finished task 0.0 in stage 1.0 (TID 1) in 35 ms on localhost (1/1)
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.DAGScheduler]ResultStage 1 (collect at SparkUpperServiceImpl.java:64) finished in 0.035 s
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.TaskSchedulerImpl]Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.DAGScheduler]Job 1 finished: collect at SparkUpperServiceImpl.java:64, took 0.042814 s
[INFO] [2018-10-22 12:25:44][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@2b2948e2: startup date [Mon Oct 22 12:25:37 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 12:25:44][org.apache.spark.SparkContext]Invoking stop() from shutdown hook
[INFO] [2018-10-22 12:25:44][org.apache.spark.SparkContext]SparkContext already stopped.
[INFO] [2018-10-22 12:25:44][org.apache.spark.storage.DiskBlockManager]Shutdown hook called
[INFO] [2018-10-22 12:25:44][org.apache.spark.util.ShutdownHookManager]Shutdown hook called
[INFO] [2018-10-22 12:25:44][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-ab543c08-7429-4cb3-9fe8-2b081464e416
[INFO] [2018-10-22 12:25:44][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-ab543c08-7429-4cb3-9fe8-2b081464e416\userFiles-8448c5c7-c8e3-4e22-a5ef-0388cc773901
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/static/sql,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/execution/json,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/execution,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/json,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO] [2018-10-22 12:25:44][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO] [2018-10-22 12:25:44][org.apache.spark.ui.SparkUI]Stopped Spark web UI at http://192.168.68.1:4040
[INFO] [2018-10-22 12:25:44][org.apache.spark.MapOutputTrackerMasterEndpoint]MapOutputTrackerMasterEndpoint stopped!
[INFO] [2018-10-22 12:25:44][org.apache.spark.storage.MemoryStore]MemoryStore cleared
[INFO] [2018-10-22 12:25:44][org.apache.spark.storage.BlockManager]BlockManager stopped
[INFO] [2018-10-22 12:25:44][org.apache.spark.storage.BlockManagerMaster]BlockManagerMaster stopped
[INFO] [2018-10-22 12:25:44][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint]OutputCommitCoordinator stopped!
[INFO] [2018-10-22 12:25:44][org.apache.spark.SparkContext]Successfully stopped SparkContext
[INFO] [2018-10-22 12:46:00][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-22 12:46:00][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@57536d79: startup date [Mon Oct 22 12:46:00 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 12:46:00][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-22 12:46:00][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-22 12:46:00][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-22 12:46:00][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-22 12:46:01][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-22 12:46:01][org.apache.spark.SparkContext]Running Spark version 1.6.0
[WARN] [2018-10-22 12:46:01][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] [2018-10-22 12:46:02][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-22 12:46:02][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-22 12:46:02][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(rym2017); users with modify permissions: Set(rym2017)
[INFO] [2018-10-22 12:46:02][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 14577.
[INFO] [2018-10-22 12:46:03][akka.event.slf4j.Slf4jLogger]Slf4jLogger started
[INFO] [2018-10-22 12:46:03][Remoting]Starting remoting
[INFO] [2018-10-22 12:46:03][Remoting]Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.1:14591]
[INFO] [2018-10-22 12:46:03][org.apache.spark.util.Utils]Successfully started service 'sparkDriverActorSystem' on port 14591.
[INFO] [2018-10-22 12:46:03][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-22 12:46:03][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-22 12:46:03][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-39909b07-250f-4628-8ca8-636af001d6e5
[INFO] [2018-10-22 12:46:03][org.apache.spark.storage.MemoryStore]MemoryStore started with capacity 3.8 GB
[INFO] [2018-10-22 12:46:03][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-22 12:46:03][org.spark-project.jetty.server.Server]jetty-8.y.z-SNAPSHOT
[INFO] [2018-10-22 12:46:04][org.spark-project.jetty.server.AbstractConnector]Started SelectChannelConnector@0.0.0.0:4040
[INFO] [2018-10-22 12:46:04][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-22 12:46:04][org.apache.spark.ui.SparkUI]Started SparkUI at http://192.168.68.1:4040
[INFO] [2018-10-22 12:46:04][org.apache.spark.executor.Executor]Starting executor ID driver on host localhost
[INFO] [2018-10-22 12:46:04][org.apache.spark.util.Utils]Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 14601.
[INFO] [2018-10-22 12:46:04][org.apache.spark.network.netty.NettyBlockTransferService]Server created on 14601
[INFO] [2018-10-22 12:46:04][org.apache.spark.storage.BlockManagerMaster]Trying to register BlockManager
[INFO] [2018-10-22 12:46:04][org.apache.spark.storage.BlockManagerMasterEndpoint]Registering block manager localhost:14601 with 3.8 GB RAM, BlockManagerId(driver, localhost, 14601)
[INFO] [2018-10-22 12:46:04][org.apache.spark.storage.BlockManagerMaster]Registered BlockManager
[INFO] [2018-10-22 12:46:04][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this url:jdbc:mysql://192.168.68.244:3306/test?useUnicode=true&characterEncoding=UTF-8
[INFO] [2018-10-22 12:46:04][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this table:testtable
[INFO] [2018-10-22 12:46:04][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this master:local
[INFO] [2018-10-22 12:46:04][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this username:root
[INFO] [2018-10-22 12:46:04][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this password:root
[INFO] [2018-10-22 12:46:07][org.apache.spark.SparkContext]Starting job: show at SparkUpperServiceImpl.java:63
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.DAGScheduler]Got job 0 (show at SparkUpperServiceImpl.java:63) with 1 output partitions
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.DAGScheduler]Final stage: ResultStage 0 (show at SparkUpperServiceImpl.java:63)
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.DAGScheduler]Parents of final stage: List()
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.DAGScheduler]Missing parents: List()
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.DAGScheduler]Submitting ResultStage 0 (MapPartitionsRDD[1] at show at SparkUpperServiceImpl.java:63), which has no missing parents
[INFO] [2018-10-22 12:46:07][org.apache.spark.storage.MemoryStore]Block broadcast_0 stored as values in memory (estimated size 4.8 KB, free 4.8 KB)
[INFO] [2018-10-22 12:46:07][org.apache.spark.storage.MemoryStore]Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.3 KB, free 7.1 KB)
[INFO] [2018-10-22 12:46:07][org.apache.spark.storage.BlockManagerInfo]Added broadcast_0_piece0 in memory on localhost:14601 (size: 2.3 KB, free: 3.8 GB)
[INFO] [2018-10-22 12:46:07][org.apache.spark.SparkContext]Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.DAGScheduler]Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at show at SparkUpperServiceImpl.java:63)
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.TaskSchedulerImpl]Adding task set 0.0 with 1 tasks
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.TaskSetManager]Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 1841 bytes)
[INFO] [2018-10-22 12:46:07][org.apache.spark.executor.Executor]Running task 0.0 in stage 0.0 (TID 0)
[INFO] [2018-10-22 12:46:07][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD]closed connection
[INFO] [2018-10-22 12:46:07][org.apache.spark.executor.Executor]Finished task 0.0 in stage 0.0 (TID 0). 1572 bytes result sent to driver
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.TaskSetManager]Finished task 0.0 in stage 0.0 (TID 0) in 107 ms on localhost (1/1)
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.TaskSchedulerImpl]Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.DAGScheduler]ResultStage 0 (show at SparkUpperServiceImpl.java:63) finished in 0.120 s
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.DAGScheduler]Job 0 finished: show at SparkUpperServiceImpl.java:63, took 0.297515 s
[INFO] [2018-10-22 12:46:07][org.apache.spark.SparkContext]Starting job: collect at SparkUpperServiceImpl.java:64
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.DAGScheduler]Got job 1 (collect at SparkUpperServiceImpl.java:64) with 1 output partitions
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.DAGScheduler]Final stage: ResultStage 1 (collect at SparkUpperServiceImpl.java:64)
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.DAGScheduler]Parents of final stage: List()
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.DAGScheduler]Missing parents: List()
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.DAGScheduler]Submitting ResultStage 1 (MapPartitionsRDD[3] at javaRDD at SparkUpperServiceImpl.java:64), which has no missing parents
[INFO] [2018-10-22 12:46:07][org.apache.spark.storage.MemoryStore]Block broadcast_1 stored as values in memory (estimated size 5.0 KB, free 12.1 KB)
[INFO] [2018-10-22 12:46:07][org.apache.spark.storage.MemoryStore]Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.4 KB, free 14.5 KB)
[INFO] [2018-10-22 12:46:07][org.apache.spark.storage.BlockManagerInfo]Added broadcast_1_piece0 in memory on localhost:14601 (size: 2.4 KB, free: 3.8 GB)
[INFO] [2018-10-22 12:46:07][org.apache.spark.SparkContext]Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.DAGScheduler]Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at javaRDD at SparkUpperServiceImpl.java:64)
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.TaskSchedulerImpl]Adding task set 1.0 with 1 tasks
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.TaskSetManager]Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,PROCESS_LOCAL, 1841 bytes)
[INFO] [2018-10-22 12:46:07][org.apache.spark.executor.Executor]Running task 0.0 in stage 1.0 (TID 1)
[INFO] [2018-10-22 12:46:07][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD]closed connection
[INFO] [2018-10-22 12:46:07][org.apache.spark.executor.Executor]Finished task 0.0 in stage 1.0 (TID 1). 2363 bytes result sent to driver
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.TaskSetManager]Finished task 0.0 in stage 1.0 (TID 1) in 37 ms on localhost (1/1)
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.TaskSchedulerImpl]Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.DAGScheduler]ResultStage 1 (collect at SparkUpperServiceImpl.java:64) finished in 0.037 s
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.DAGScheduler]Job 1 finished: collect at SparkUpperServiceImpl.java:64, took 0.046135 s
[INFO] [2018-10-22 12:46:07][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@57536d79: startup date [Mon Oct 22 12:46:00 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 12:46:07][org.apache.spark.SparkContext]Invoking stop() from shutdown hook
[INFO] [2018-10-22 12:46:07][org.apache.spark.SparkContext]SparkContext already stopped.
[INFO] [2018-10-22 12:46:07][org.apache.spark.storage.DiskBlockManager]Shutdown hook called
[INFO] [2018-10-22 12:46:07][org.apache.spark.util.ShutdownHookManager]Shutdown hook called
[INFO] [2018-10-22 12:46:07][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-b14698c8-ce7d-4542-b823-ccd6ac00a4d8
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/static/sql,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/execution/json,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/execution,null}
[INFO] [2018-10-22 12:46:07][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-b14698c8-ce7d-4542-b823-ccd6ac00a4d8\userFiles-438c715f-dd2a-476c-83f1-46c6c48cb005
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/json,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO] [2018-10-22 12:46:07][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO] [2018-10-22 12:46:07][org.apache.spark.ui.SparkUI]Stopped Spark web UI at http://192.168.68.1:4040
[INFO] [2018-10-22 12:46:07][org.apache.spark.MapOutputTrackerMasterEndpoint]MapOutputTrackerMasterEndpoint stopped!
[INFO] [2018-10-22 12:46:07][org.apache.spark.storage.MemoryStore]MemoryStore cleared
[INFO] [2018-10-22 12:46:07][org.apache.spark.storage.BlockManager]BlockManager stopped
[INFO] [2018-10-22 12:46:07][org.apache.spark.storage.BlockManagerMaster]BlockManagerMaster stopped
[INFO] [2018-10-22 12:46:07][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint]OutputCommitCoordinator stopped!
[INFO] [2018-10-22 12:46:07][org.apache.spark.SparkContext]Successfully stopped SparkContext
[INFO] [2018-10-22 12:46:07][akka.remote.RemoteActorRefProvider$RemotingTerminator]Shutting down remote daemon.
[INFO] [2018-10-22 12:46:20][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-22 12:46:20][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@57536d79: startup date [Mon Oct 22 12:46:20 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 12:46:20][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-22 12:46:20][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-22 12:46:20][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-22 12:46:20][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-22 12:46:21][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-22 12:46:21][org.apache.spark.SparkContext]Running Spark version 1.6.0
[WARN] [2018-10-22 12:46:21][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] [2018-10-22 12:46:21][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-22 12:46:21][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-22 12:46:21][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(rym2017); users with modify permissions: Set(rym2017)
[INFO] [2018-10-22 12:46:22][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 14655.
[INFO] [2018-10-22 12:46:23][akka.event.slf4j.Slf4jLogger]Slf4jLogger started
[INFO] [2018-10-22 12:46:23][Remoting]Starting remoting
[INFO] [2018-10-22 12:46:23][Remoting]Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.1:14669]
[INFO] [2018-10-22 12:46:23][org.apache.spark.util.Utils]Successfully started service 'sparkDriverActorSystem' on port 14669.
[INFO] [2018-10-22 12:46:23][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-22 12:46:23][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-22 12:46:23][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-dcff8757-39c9-4bee-a513-c4bb1afa7c80
[INFO] [2018-10-22 12:46:23][org.apache.spark.storage.MemoryStore]MemoryStore started with capacity 3.8 GB
[INFO] [2018-10-22 12:46:23][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-22 12:46:23][org.spark-project.jetty.server.Server]jetty-8.y.z-SNAPSHOT
[INFO] [2018-10-22 12:46:23][org.spark-project.jetty.server.AbstractConnector]Started SelectChannelConnector@0.0.0.0:4040
[INFO] [2018-10-22 12:46:23][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-22 12:46:23][org.apache.spark.ui.SparkUI]Started SparkUI at http://192.168.68.1:4040
[INFO] [2018-10-22 12:46:23][org.apache.spark.executor.Executor]Starting executor ID driver on host localhost
[INFO] [2018-10-22 12:46:24][org.apache.spark.util.Utils]Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 14678.
[INFO] [2018-10-22 12:46:24][org.apache.spark.network.netty.NettyBlockTransferService]Server created on 14678
[INFO] [2018-10-22 12:46:24][org.apache.spark.storage.BlockManagerMaster]Trying to register BlockManager
[INFO] [2018-10-22 12:46:24][org.apache.spark.storage.BlockManagerMasterEndpoint]Registering block manager localhost:14678 with 3.8 GB RAM, BlockManagerId(driver, localhost, 14678)
[INFO] [2018-10-22 12:46:24][org.apache.spark.storage.BlockManagerMaster]Registered BlockManager
[INFO] [2018-10-22 12:46:24][com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource]Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 3, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, dataSourceName -> 1hgeebl9y16r7pkoervh8x|2e377400, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> com.mysql.jdbc.Driver, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, identityToken -> 1hgeebl9y16r7pkoervh8x|2e377400, idleConnectionTestPeriod -> 0, initialPoolSize -> 1, jdbcUrl -> jdbc:mysql://192.168.68.244:3306/test, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 20, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 1, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, numThreadsAwaitingCheckoutDefaultUser -> 0, preferredTestQuery -> null, properties -> {user=******, password=******}, propertyCycle -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false ]
[INFO] [2018-10-22 12:46:24][com.harleycorp.testmybatis.TestMyBatis][{"age":23,"id":1,"password":"000000","userName":"lisa"},{"age":22,"id":2,"password":"123456","userName":"jack"}]
[INFO] [2018-10-22 12:46:24][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@57536d79: startup date [Mon Oct 22 12:46:20 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 12:46:24][org.apache.spark.SparkContext]Invoking stop() from shutdown hook
[INFO] [2018-10-22 12:46:24][org.apache.spark.SparkContext]SparkContext already stopped.
[INFO] [2018-10-22 12:46:24][org.apache.spark.storage.DiskBlockManager]Shutdown hook called
[INFO] [2018-10-22 12:46:25][org.apache.spark.util.ShutdownHookManager]Shutdown hook called
[INFO] [2018-10-22 12:46:25][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-f168d736-4c0f-4216-a194-17d2a64289f0\userFiles-53898431-02bf-4062-ba84-93a36e50de4e
[INFO] [2018-10-22 12:46:25][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-f168d736-4c0f-4216-a194-17d2a64289f0
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/static/sql,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/execution/json,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/execution,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/json,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO] [2018-10-22 12:46:25][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO] [2018-10-22 12:46:25][org.apache.spark.ui.SparkUI]Stopped Spark web UI at http://192.168.68.1:4040
[INFO] [2018-10-22 12:46:25][org.apache.spark.MapOutputTrackerMasterEndpoint]MapOutputTrackerMasterEndpoint stopped!
[INFO] [2018-10-22 12:46:25][org.apache.spark.storage.MemoryStore]MemoryStore cleared
[INFO] [2018-10-22 12:46:25][org.apache.spark.storage.BlockManager]BlockManager stopped
[INFO] [2018-10-22 12:46:25][org.apache.spark.storage.BlockManagerMaster]BlockManagerMaster stopped
[INFO] [2018-10-22 12:46:25][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint]OutputCommitCoordinator stopped!
[INFO] [2018-10-22 12:46:25][org.apache.spark.SparkContext]Successfully stopped SparkContext
[INFO] [2018-10-22 14:06:28][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-22 14:06:28][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@3fa3a66c: startup date [Mon Oct 22 14:06:28 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 14:06:29][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-22 14:06:29][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-22 14:06:29][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-22 14:06:29][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-22 14:06:29][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-22 14:06:30][org.apache.spark.SparkContext]Running Spark version 1.6.0
[WARN] [2018-10-22 14:06:39][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] [2018-10-22 14:06:39][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-22 14:06:39][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-22 14:06:39][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(rym2017); users with modify permissions: Set(rym2017)
[INFO] [2018-10-22 14:06:40][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 10441.
[INFO] [2018-10-22 14:06:40][akka.event.slf4j.Slf4jLogger]Slf4jLogger started
[INFO] [2018-10-22 14:06:40][Remoting]Starting remoting
[INFO] [2018-10-22 14:06:41][Remoting]Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.1:10454]
[INFO] [2018-10-22 14:06:41][org.apache.spark.util.Utils]Successfully started service 'sparkDriverActorSystem' on port 10454.
[INFO] [2018-10-22 14:06:41][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-22 14:06:41][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-22 14:06:41][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-1983bf0c-de4d-4829-8916-c03a5c790680
[INFO] [2018-10-22 14:06:41][org.apache.spark.storage.MemoryStore]MemoryStore started with capacity 3.8 GB
[INFO] [2018-10-22 14:06:41][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-22 14:06:41][org.spark-project.jetty.server.Server]jetty-8.y.z-SNAPSHOT
[INFO] [2018-10-22 14:06:41][org.spark-project.jetty.server.AbstractConnector]Started SelectChannelConnector@0.0.0.0:4040
[INFO] [2018-10-22 14:06:41][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-22 14:06:41][org.apache.spark.ui.SparkUI]Started SparkUI at http://192.168.68.1:4040
[INFO] [2018-10-22 14:06:41][org.apache.spark.deploy.client.AppClient$ClientEndpoint]Connecting to master spark://192.168.68.244:7077...
[WARN] [2018-10-22 14:06:41][org.apache.spark.deploy.client.AppClient$ClientEndpoint]Failed to connect to master 192.168.68.244:7077
java.lang.RuntimeException: java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at java.io.DataInputStream.readUTF(DataInputStream.java:609)
	at java.io.DataInputStream.readUTF(DataInputStream.java:564)
	at org.apache.spark.rpc.netty.RequestMessage$.readRpcAddress(NettyRpcEnv.scala:585)
	at org.apache.spark.rpc.netty.RequestMessage$.apply(NettyRpcEnv.scala:595)
	at org.apache.spark.rpc.netty.NettyRpcHandler.internalReceive(NettyRpcEnv.scala:654)
	at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:639)
	at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:157)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:105)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)

	at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:186)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:106)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:744)
[INFO] [2018-10-22 14:07:01][org.apache.spark.deploy.client.AppClient$ClientEndpoint]Connecting to master spark://192.168.68.244:7077...
[WARN] [2018-10-22 14:07:01][org.apache.spark.deploy.client.AppClient$ClientEndpoint]Failed to connect to master 192.168.68.244:7077
java.lang.RuntimeException: java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at java.io.DataInputStream.readUTF(DataInputStream.java:609)
	at java.io.DataInputStream.readUTF(DataInputStream.java:564)
	at org.apache.spark.rpc.netty.RequestMessage$.readRpcAddress(NettyRpcEnv.scala:585)
	at org.apache.spark.rpc.netty.RequestMessage$.apply(NettyRpcEnv.scala:595)
	at org.apache.spark.rpc.netty.NettyRpcHandler.internalReceive(NettyRpcEnv.scala:654)
	at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:639)
	at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:157)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:105)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)

	at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:186)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:106)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:744)
[INFO] [2018-10-22 14:37:21][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-22 14:37:22][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@cd2b045: startup date [Mon Oct 22 14:37:22 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 14:38:37][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-22 14:38:38][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@11031d18: startup date [Mon Oct 22 14:38:38 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 14:38:38][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-22 14:38:38][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-22 14:38:38][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-22 14:38:38][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-22 14:38:38][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-22 14:38:39][org.apache.spark.SparkContext]Running Spark version 1.6.0
[WARN] [2018-10-22 14:38:48][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] [2018-10-22 14:38:48][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-22 14:38:48][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-22 14:38:48][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(rym2017); users with modify permissions: Set(rym2017)
[INFO] [2018-10-22 14:38:49][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 13109.
[INFO] [2018-10-22 14:38:50][akka.event.slf4j.Slf4jLogger]Slf4jLogger started
[INFO] [2018-10-22 14:38:50][Remoting]Starting remoting
[INFO] [2018-10-22 14:38:50][Remoting]Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.1:13123]
[INFO] [2018-10-22 14:38:50][org.apache.spark.util.Utils]Successfully started service 'sparkDriverActorSystem' on port 13123.
[INFO] [2018-10-22 14:38:50][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-22 14:38:50][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-22 14:38:50][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-8bbf9177-8523-42c8-bb3b-035172c5db59
[INFO] [2018-10-22 14:38:50][org.apache.spark.storage.MemoryStore]MemoryStore started with capacity 3.8 GB
[INFO] [2018-10-22 14:38:50][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-22 14:38:50][org.spark-project.jetty.server.Server]jetty-8.y.z-SNAPSHOT
[INFO] [2018-10-22 14:38:50][org.spark-project.jetty.server.AbstractConnector]Started SelectChannelConnector@0.0.0.0:4040
[INFO] [2018-10-22 14:38:50][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-22 14:38:50][org.apache.spark.ui.SparkUI]Started SparkUI at http://192.168.68.1:4040
[INFO] [2018-10-22 14:38:50][org.apache.spark.executor.Executor]Starting executor ID driver on host localhost
[INFO] [2018-10-22 14:38:50][org.apache.spark.util.Utils]Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 13132.
[INFO] [2018-10-22 14:38:50][org.apache.spark.network.netty.NettyBlockTransferService]Server created on 13132
[INFO] [2018-10-22 14:38:51][org.apache.spark.storage.BlockManagerMaster]Trying to register BlockManager
[INFO] [2018-10-22 14:38:51][org.apache.spark.storage.BlockManagerMasterEndpoint]Registering block manager localhost:13132 with 3.8 GB RAM, BlockManagerId(driver, localhost, 13132)
[INFO] [2018-10-22 14:38:51][org.apache.spark.storage.BlockManagerMaster]Registered BlockManager
[INFO] [2018-10-22 14:38:51][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this url:jdbc:mysql://192.168.68.244:3306/test?useUnicode=true&characterEncoding=UTF-8
[INFO] [2018-10-22 14:38:51][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this table:testtable
[INFO] [2018-10-22 14:38:51][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this username:root
[INFO] [2018-10-22 14:38:51][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this password:root
[INFO] [2018-10-22 14:38:54][org.apache.spark.SparkContext]Starting job: show at SparkUpperServiceImpl.java:64
[INFO] [2018-10-22 14:38:54][org.apache.spark.scheduler.DAGScheduler]Got job 0 (show at SparkUpperServiceImpl.java:64) with 1 output partitions
[INFO] [2018-10-22 14:38:54][org.apache.spark.scheduler.DAGScheduler]Final stage: ResultStage 0 (show at SparkUpperServiceImpl.java:64)
[INFO] [2018-10-22 14:38:54][org.apache.spark.scheduler.DAGScheduler]Parents of final stage: List()
[INFO] [2018-10-22 14:38:54][org.apache.spark.scheduler.DAGScheduler]Missing parents: List()
[INFO] [2018-10-22 14:38:54][org.apache.spark.scheduler.DAGScheduler]Submitting ResultStage 0 (MapPartitionsRDD[1] at show at SparkUpperServiceImpl.java:64), which has no missing parents
[INFO] [2018-10-22 14:38:54][org.apache.spark.storage.MemoryStore]Block broadcast_0 stored as values in memory (estimated size 4.8 KB, free 4.8 KB)
[INFO] [2018-10-22 14:38:54][org.apache.spark.storage.MemoryStore]Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.3 KB, free 7.1 KB)
[INFO] [2018-10-22 14:38:54][org.apache.spark.storage.BlockManagerInfo]Added broadcast_0_piece0 in memory on localhost:13132 (size: 2.3 KB, free: 3.8 GB)
[INFO] [2018-10-22 14:38:54][org.apache.spark.SparkContext]Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO] [2018-10-22 14:38:54][org.apache.spark.scheduler.DAGScheduler]Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at show at SparkUpperServiceImpl.java:64)
[INFO] [2018-10-22 14:38:54][org.apache.spark.scheduler.TaskSchedulerImpl]Adding task set 0.0 with 1 tasks
[INFO] [2018-10-22 14:38:54][org.apache.spark.scheduler.TaskSetManager]Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 1841 bytes)
[INFO] [2018-10-22 14:38:54][org.apache.spark.executor.Executor]Running task 0.0 in stage 0.0 (TID 0)
[INFO] [2018-10-22 14:38:54][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD]closed connection
[INFO] [2018-10-22 14:38:54][org.apache.spark.executor.Executor]Finished task 0.0 in stage 0.0 (TID 0). 1572 bytes result sent to driver
[INFO] [2018-10-22 14:38:54][org.apache.spark.scheduler.TaskSetManager]Finished task 0.0 in stage 0.0 (TID 0) in 157 ms on localhost (1/1)
[INFO] [2018-10-22 14:38:54][org.apache.spark.scheduler.TaskSchedulerImpl]Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] [2018-10-22 14:38:54][org.apache.spark.scheduler.DAGScheduler]ResultStage 0 (show at SparkUpperServiceImpl.java:64) finished in 0.175 s
[INFO] [2018-10-22 14:38:54][org.apache.spark.scheduler.DAGScheduler]Job 0 finished: show at SparkUpperServiceImpl.java:64, took 0.368447 s
[INFO] [2018-10-22 14:38:55][org.apache.spark.SparkContext]Starting job: collect at SparkUpperServiceImpl.java:65
[INFO] [2018-10-22 14:38:55][org.apache.spark.scheduler.DAGScheduler]Got job 1 (collect at SparkUpperServiceImpl.java:65) with 1 output partitions
[INFO] [2018-10-22 14:38:55][org.apache.spark.scheduler.DAGScheduler]Final stage: ResultStage 1 (collect at SparkUpperServiceImpl.java:65)
[INFO] [2018-10-22 14:38:55][org.apache.spark.scheduler.DAGScheduler]Parents of final stage: List()
[INFO] [2018-10-22 14:38:55][org.apache.spark.scheduler.DAGScheduler]Missing parents: List()
[INFO] [2018-10-22 14:38:55][org.apache.spark.scheduler.DAGScheduler]Submitting ResultStage 1 (MapPartitionsRDD[3] at javaRDD at SparkUpperServiceImpl.java:65), which has no missing parents
[INFO] [2018-10-22 14:38:55][org.apache.spark.storage.MemoryStore]Block broadcast_1 stored as values in memory (estimated size 5.0 KB, free 12.1 KB)
[INFO] [2018-10-22 14:38:55][org.apache.spark.storage.MemoryStore]Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.4 KB, free 14.5 KB)
[INFO] [2018-10-22 14:38:55][org.apache.spark.storage.BlockManagerInfo]Added broadcast_1_piece0 in memory on localhost:13132 (size: 2.4 KB, free: 3.8 GB)
[INFO] [2018-10-22 14:38:55][org.apache.spark.SparkContext]Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO] [2018-10-22 14:38:55][org.apache.spark.scheduler.DAGScheduler]Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at javaRDD at SparkUpperServiceImpl.java:65)
[INFO] [2018-10-22 14:38:55][org.apache.spark.scheduler.TaskSchedulerImpl]Adding task set 1.0 with 1 tasks
[INFO] [2018-10-22 14:38:55][org.apache.spark.scheduler.TaskSetManager]Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,PROCESS_LOCAL, 1841 bytes)
[INFO] [2018-10-22 14:38:55][org.apache.spark.executor.Executor]Running task 0.0 in stage 1.0 (TID 1)
[INFO] [2018-10-22 14:38:55][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD]closed connection
[INFO] [2018-10-22 14:38:55][org.apache.spark.executor.Executor]Finished task 0.0 in stage 1.0 (TID 1). 2363 bytes result sent to driver
[INFO] [2018-10-22 14:38:55][org.apache.spark.scheduler.TaskSetManager]Finished task 0.0 in stage 1.0 (TID 1) in 39 ms on localhost (1/1)
[INFO] [2018-10-22 14:38:55][org.apache.spark.scheduler.DAGScheduler]ResultStage 1 (collect at SparkUpperServiceImpl.java:65) finished in 0.040 s
[INFO] [2018-10-22 14:38:55][org.apache.spark.scheduler.TaskSchedulerImpl]Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO] [2018-10-22 14:38:55][org.apache.spark.scheduler.DAGScheduler]Job 1 finished: collect at SparkUpperServiceImpl.java:65, took 0.052218 s
[INFO] [2018-10-22 14:38:55][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@11031d18: startup date [Mon Oct 22 14:38:38 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 14:38:55][org.apache.spark.storage.DiskBlockManager]Shutdown hook called
[INFO] [2018-10-22 14:38:55][org.apache.spark.util.ShutdownHookManager]Shutdown hook called
[INFO] [2018-10-22 14:38:55][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-2427beb0-cfd7-4df3-8a6a-f4fe71ebd2dc\userFiles-a45fa5c0-8500-4b8c-9543-7628e1b5b261
[INFO] [2018-10-22 14:38:55][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-2427beb0-cfd7-4df3-8a6a-f4fe71ebd2dc
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/static/sql,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/execution/json,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/execution,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/json,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO] [2018-10-22 14:38:55][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO] [2018-10-22 14:38:55][org.apache.spark.ui.SparkUI]Stopped Spark web UI at http://192.168.68.1:4040
[INFO] [2018-10-22 14:38:55][org.apache.spark.MapOutputTrackerMasterEndpoint]MapOutputTrackerMasterEndpoint stopped!
[INFO] [2018-10-22 14:38:55][org.apache.spark.storage.MemoryStore]MemoryStore cleared
[INFO] [2018-10-22 14:38:55][org.apache.spark.storage.BlockManager]BlockManager stopped
[INFO] [2018-10-22 14:38:55][org.apache.spark.storage.BlockManagerMaster]BlockManagerMaster stopped
[INFO] [2018-10-22 14:38:55][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint]OutputCommitCoordinator stopped!
[INFO] [2018-10-22 14:38:55][org.apache.spark.SparkContext]Successfully stopped SparkContext
[INFO] [2018-10-22 14:55:09][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-22 14:55:09][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@11031d18: startup date [Mon Oct 22 14:55:09 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 14:55:09][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-22 14:55:09][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-22 14:55:09][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-22 14:55:09][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-22 14:55:09][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-22 14:55:10][org.apache.spark.SparkContext]Running Spark version 1.6.0
[WARN] [2018-10-22 14:55:19][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] [2018-10-22 14:55:19][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-22 14:55:19][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-22 14:55:19][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(rym2017); users with modify permissions: Set(rym2017)
[INFO] [2018-10-22 14:55:20][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 14319.
[INFO] [2018-10-22 14:55:21][akka.event.slf4j.Slf4jLogger]Slf4jLogger started
[INFO] [2018-10-22 14:55:21][Remoting]Starting remoting
[INFO] [2018-10-22 14:55:21][Remoting]Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.1:14332]
[INFO] [2018-10-22 14:55:21][org.apache.spark.util.Utils]Successfully started service 'sparkDriverActorSystem' on port 14332.
[INFO] [2018-10-22 14:55:21][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-22 14:55:21][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-22 14:55:21][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-edda7570-fb10-459f-a150-715c24ed9c07
[INFO] [2018-10-22 14:55:21][org.apache.spark.storage.MemoryStore]MemoryStore started with capacity 3.8 GB
[INFO] [2018-10-22 14:55:21][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-22 14:55:21][org.spark-project.jetty.server.Server]jetty-8.y.z-SNAPSHOT
[INFO] [2018-10-22 14:55:21][org.spark-project.jetty.server.AbstractConnector]Started SelectChannelConnector@0.0.0.0:4040
[INFO] [2018-10-22 14:55:21][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-22 14:55:21][org.apache.spark.ui.SparkUI]Started SparkUI at http://192.168.68.1:4040
[INFO] [2018-10-22 14:55:22][org.apache.spark.deploy.client.AppClient$ClientEndpoint]Connecting to master spark://192.168.68.244:7077...
[WARN] [2018-10-22 14:55:22][org.apache.spark.deploy.client.AppClient$ClientEndpoint]Failed to connect to master 192.168.68.244:7077
java.lang.RuntimeException: java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at java.io.DataInputStream.readUTF(DataInputStream.java:609)
	at java.io.DataInputStream.readUTF(DataInputStream.java:564)
	at org.apache.spark.rpc.netty.RequestMessage$.readRpcAddress(NettyRpcEnv.scala:585)
	at org.apache.spark.rpc.netty.RequestMessage$.apply(NettyRpcEnv.scala:595)
	at org.apache.spark.rpc.netty.NettyRpcHandler.internalReceive(NettyRpcEnv.scala:654)
	at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:639)
	at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:157)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:105)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)

	at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:186)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:106)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:744)
[INFO] [2018-10-22 14:55:42][org.apache.spark.deploy.client.AppClient$ClientEndpoint]Connecting to master spark://192.168.68.244:7077...
[WARN] [2018-10-22 14:55:42][org.apache.spark.deploy.client.AppClient$ClientEndpoint]Failed to connect to master 192.168.68.244:7077
java.lang.RuntimeException: java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at java.io.DataInputStream.readUTF(DataInputStream.java:609)
	at java.io.DataInputStream.readUTF(DataInputStream.java:564)
	at org.apache.spark.rpc.netty.RequestMessage$.readRpcAddress(NettyRpcEnv.scala:585)
	at org.apache.spark.rpc.netty.RequestMessage$.apply(NettyRpcEnv.scala:595)
	at org.apache.spark.rpc.netty.NettyRpcHandler.internalReceive(NettyRpcEnv.scala:654)
	at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:639)
	at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:157)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:105)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)

	at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:186)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:106)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:744)
[INFO] [2018-10-22 14:56:05][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-22 14:56:05][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@11031d18: startup date [Mon Oct 22 14:56:05 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 14:56:05][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-22 14:56:05][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-22 14:56:05][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-22 14:56:06][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-22 14:56:06][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-22 14:56:06][org.apache.spark.SparkContext]Running Spark version 1.6.0
[WARN] [2018-10-22 14:56:16][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] [2018-10-22 14:56:16][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-22 14:56:16][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-22 14:56:16][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(rym2017); users with modify permissions: Set(rym2017)
[INFO] [2018-10-22 14:56:17][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 14424.
[INFO] [2018-10-22 14:56:17][akka.event.slf4j.Slf4jLogger]Slf4jLogger started
[INFO] [2018-10-22 14:56:17][Remoting]Starting remoting
[INFO] [2018-10-22 14:56:17][Remoting]Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.1:14438]
[INFO] [2018-10-22 14:56:17][org.apache.spark.util.Utils]Successfully started service 'sparkDriverActorSystem' on port 14438.
[INFO] [2018-10-22 14:56:17][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-22 14:56:17][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-22 14:56:18][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-8bb16a63-dd36-47b3-ab16-ea2ebdf61c6e
[INFO] [2018-10-22 14:56:18][org.apache.spark.storage.MemoryStore]MemoryStore started with capacity 3.8 GB
[INFO] [2018-10-22 14:56:18][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-22 14:56:18][org.spark-project.jetty.server.Server]jetty-8.y.z-SNAPSHOT
[INFO] [2018-10-22 14:56:18][org.spark-project.jetty.server.AbstractConnector]Started SelectChannelConnector@0.0.0.0:4040
[INFO] [2018-10-22 14:56:18][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-22 14:56:18][org.apache.spark.ui.SparkUI]Started SparkUI at http://192.168.68.1:4040
[INFO] [2018-10-22 14:56:18][org.apache.spark.executor.Executor]Starting executor ID driver on host localhost
[INFO] [2018-10-22 14:56:18][org.apache.spark.util.Utils]Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 14447.
[INFO] [2018-10-22 14:56:18][org.apache.spark.network.netty.NettyBlockTransferService]Server created on 14447
[INFO] [2018-10-22 14:56:18][org.apache.spark.storage.BlockManagerMaster]Trying to register BlockManager
[INFO] [2018-10-22 14:56:18][org.apache.spark.storage.BlockManagerMasterEndpoint]Registering block manager localhost:14447 with 3.8 GB RAM, BlockManagerId(driver, localhost, 14447)
[INFO] [2018-10-22 14:56:18][org.apache.spark.storage.BlockManagerMaster]Registered BlockManager
[INFO] [2018-10-22 14:56:19][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this url:jdbc:mysql://192.168.68.244:3306/test?useUnicode=true&characterEncoding=UTF-8
[INFO] [2018-10-22 14:56:19][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this table:testtable
[INFO] [2018-10-22 14:56:19][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this username:root
[INFO] [2018-10-22 14:56:19][com.harleycorp.service.impl.SparkUpperServiceImpl]=======================this password:root
[INFO] [2018-10-22 14:56:22][org.apache.spark.SparkContext]Starting job: show at SparkUpperServiceImpl.java:64
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.DAGScheduler]Got job 0 (show at SparkUpperServiceImpl.java:64) with 1 output partitions
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.DAGScheduler]Final stage: ResultStage 0 (show at SparkUpperServiceImpl.java:64)
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.DAGScheduler]Parents of final stage: List()
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.DAGScheduler]Missing parents: List()
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.DAGScheduler]Submitting ResultStage 0 (MapPartitionsRDD[1] at show at SparkUpperServiceImpl.java:64), which has no missing parents
[INFO] [2018-10-22 14:56:22][org.apache.spark.storage.MemoryStore]Block broadcast_0 stored as values in memory (estimated size 4.8 KB, free 4.8 KB)
[INFO] [2018-10-22 14:56:22][org.apache.spark.storage.MemoryStore]Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.3 KB, free 7.1 KB)
[INFO] [2018-10-22 14:56:22][org.apache.spark.storage.BlockManagerInfo]Added broadcast_0_piece0 in memory on localhost:14447 (size: 2.3 KB, free: 3.8 GB)
[INFO] [2018-10-22 14:56:22][org.apache.spark.SparkContext]Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.DAGScheduler]Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at show at SparkUpperServiceImpl.java:64)
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.TaskSchedulerImpl]Adding task set 0.0 with 1 tasks
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.TaskSetManager]Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 1841 bytes)
[INFO] [2018-10-22 14:56:22][org.apache.spark.executor.Executor]Running task 0.0 in stage 0.0 (TID 0)
[INFO] [2018-10-22 14:56:22][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD]closed connection
[INFO] [2018-10-22 14:56:22][org.apache.spark.executor.Executor]Finished task 0.0 in stage 0.0 (TID 0). 1572 bytes result sent to driver
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.TaskSetManager]Finished task 0.0 in stage 0.0 (TID 0) in 156 ms on localhost (1/1)
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.TaskSchedulerImpl]Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.DAGScheduler]ResultStage 0 (show at SparkUpperServiceImpl.java:64) finished in 0.173 s
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.DAGScheduler]Job 0 finished: show at SparkUpperServiceImpl.java:64, took 0.365225 s
[INFO] [2018-10-22 14:56:22][org.apache.spark.SparkContext]Starting job: collect at SparkUpperServiceImpl.java:65
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.DAGScheduler]Got job 1 (collect at SparkUpperServiceImpl.java:65) with 1 output partitions
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.DAGScheduler]Final stage: ResultStage 1 (collect at SparkUpperServiceImpl.java:65)
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.DAGScheduler]Parents of final stage: List()
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.DAGScheduler]Missing parents: List()
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.DAGScheduler]Submitting ResultStage 1 (MapPartitionsRDD[3] at javaRDD at SparkUpperServiceImpl.java:65), which has no missing parents
[INFO] [2018-10-22 14:56:22][org.apache.spark.storage.MemoryStore]Block broadcast_1 stored as values in memory (estimated size 5.0 KB, free 12.1 KB)
[INFO] [2018-10-22 14:56:22][org.apache.spark.storage.MemoryStore]Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.4 KB, free 14.5 KB)
[INFO] [2018-10-22 14:56:22][org.apache.spark.storage.BlockManagerInfo]Added broadcast_1_piece0 in memory on localhost:14447 (size: 2.4 KB, free: 3.8 GB)
[INFO] [2018-10-22 14:56:22][org.apache.spark.SparkContext]Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.DAGScheduler]Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at javaRDD at SparkUpperServiceImpl.java:65)
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.TaskSchedulerImpl]Adding task set 1.0 with 1 tasks
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.TaskSetManager]Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,PROCESS_LOCAL, 1841 bytes)
[INFO] [2018-10-22 14:56:22][org.apache.spark.executor.Executor]Running task 0.0 in stage 1.0 (TID 1)
[INFO] [2018-10-22 14:56:22][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD]closed connection
[INFO] [2018-10-22 14:56:22][org.apache.spark.executor.Executor]Finished task 0.0 in stage 1.0 (TID 1). 2363 bytes result sent to driver
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.TaskSetManager]Finished task 0.0 in stage 1.0 (TID 1) in 32 ms on localhost (1/1)
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.DAGScheduler]ResultStage 1 (collect at SparkUpperServiceImpl.java:65) finished in 0.033 s
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.TaskSchedulerImpl]Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO] [2018-10-22 14:56:22][org.apache.spark.scheduler.DAGScheduler]Job 1 finished: collect at SparkUpperServiceImpl.java:65, took 0.042961 s
[INFO] [2018-10-22 14:56:22][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@11031d18: startup date [Mon Oct 22 14:56:05 CST 2018]; root of context hierarchy
[INFO] [2018-10-22 14:56:22][org.apache.spark.storage.DiskBlockManager]Shutdown hook called
[INFO] [2018-10-22 14:56:22][org.apache.spark.util.ShutdownHookManager]Shutdown hook called
[INFO] [2018-10-22 14:56:22][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-56f579c9-96de-4b21-a10e-473c593bc105
[INFO] [2018-10-22 14:56:22][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-56f579c9-96de-4b21-a10e-473c593bc105\userFiles-4d1e5122-6a4b-4ddf-aa99-460a60993fd4
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/static/sql,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/execution/json,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/execution,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL/json,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/SQL,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO] [2018-10-22 14:56:22][org.spark-project.jetty.server.handler.ContextHandler]stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO] [2018-10-22 14:56:22][org.apache.spark.ui.SparkUI]Stopped Spark web UI at http://192.168.68.1:4040
[INFO] [2018-10-22 14:56:23][org.apache.spark.MapOutputTrackerMasterEndpoint]MapOutputTrackerMasterEndpoint stopped!
[INFO] [2018-10-22 14:56:23][org.apache.spark.storage.MemoryStore]MemoryStore cleared
[INFO] [2018-10-22 14:56:23][org.apache.spark.storage.BlockManager]BlockManager stopped
[INFO] [2018-10-22 14:56:23][org.apache.spark.storage.BlockManagerMaster]BlockManagerMaster stopped
[INFO] [2018-10-22 14:56:23][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint]OutputCommitCoordinator stopped!
[INFO] [2018-10-22 14:56:23][org.apache.spark.SparkContext]Successfully stopped SparkContext
[INFO] [2018-10-29 21:49:30][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-29 21:49:31][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@6ffb110e: startup date [Mon Oct 29 21:49:31 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 21:49:31][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-29 21:49:31][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-29 21:49:31][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-29 21:49:31][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-29 21:49:31][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-29 21:49:32][com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource]Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 3, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, dataSourceName -> 1hgeebl9y1hap7hgkc5uhj|515f1fee, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> com.mysql.jdbc.Driver, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, identityToken -> 1hgeebl9y1hap7hgkc5uhj|515f1fee, idleConnectionTestPeriod -> 0, initialPoolSize -> 1, jdbcUrl -> jdbc:mysql://192.168.68.244:3306/myjianshu, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 20, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 1, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, numThreadsAwaitingCheckoutDefaultUser -> 0, preferredTestQuery -> null, properties -> {user=******, password=******}, propertyCycle -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false ]
[INFO] [2018-10-29 21:49:32][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@6ffb110e: startup date [Mon Oct 29 21:49:31 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 21:49:43][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-29 21:49:43][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@432dbb4b: startup date [Mon Oct 29 21:49:43 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 21:49:43][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-29 21:49:43][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-29 21:49:43][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-29 21:49:43][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-29 21:49:44][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-29 21:49:51][com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource]Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 3, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, dataSourceName -> 1hgeebl9y1haph191uf8ebv|49c7971a, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> com.mysql.jdbc.Driver, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, identityToken -> 1hgeebl9y1haph191uf8ebv|49c7971a, idleConnectionTestPeriod -> 0, initialPoolSize -> 1, jdbcUrl -> jdbc:mysql://192.168.68.244:3306/myjianshu, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 20, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 1, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, numThreadsAwaitingCheckoutDefaultUser -> 0, preferredTestQuery -> null, properties -> {user=******, password=******}, propertyCycle -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false ]
[INFO] [2018-10-29 22:07:37][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-29 22:07:37][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@79a55f23: startup date [Mon Oct 29 22:07:37 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 22:07:38][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-29 22:07:38][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-29 22:07:38][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-29 22:07:38][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-29 22:07:38][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-29 22:07:39][com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource]Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 3, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, dataSourceName -> 1hgeebl9y1hbchzigxx2x2|6ce6c876, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> com.mysql.jdbc.Driver, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, identityToken -> 1hgeebl9y1hbchzigxx2x2|6ce6c876, idleConnectionTestPeriod -> 0, initialPoolSize -> 1, jdbcUrl -> jdbc:mysql://192.168.68.244:3306/myjianshu, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 20, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 1, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, numThreadsAwaitingCheckoutDefaultUser -> 0, preferredTestQuery -> null, properties -> {user=******, password=******}, propertyCycle -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false ]
[INFO] [2018-10-29 22:07:39][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@79a55f23: startup date [Mon Oct 29 22:07:37 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 22:24:29][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-29 22:24:30][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@5c328896: startup date [Mon Oct 29 22:24:30 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 22:24:30][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-29 22:24:30][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-29 22:24:30][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-29 22:24:30][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-29 22:24:30][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[ERROR] [2018-10-29 22:24:31][org.springframework.test.context.TestContextManager]Caught exception while allowing TestExecutionListener [org.springframework.test.context.support.DependencyInjectionTestExecutionListener@36c919fe] to prepare test instance [com.harleycorp.testmybatis.TestMyBatis@4cc98ecb]
java.lang.IllegalStateException: Failed to load ApplicationContext
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContext(CacheAwareContextLoaderDelegate.java:99)
	at org.springframework.test.context.DefaultTestContext.getApplicationContext(DefaultTestContext.java:101)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:109)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:75)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:319)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:212)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:232)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:89)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:175)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'testController': Injection of resource dependencies failed; nested exception is org.springframework.beans.factory.CannotLoadBeanClassException: Error loading class [org.apache.spark.api.java.JavaSparkContext] for bean with name 'javaSparkContext' defined in class path resource [spring-mybatis.xml]: problem with class file or dependent class; nested exception is java.lang.UnsupportedClassVersionError: org/apache/spark/api/java/JavaSparkContextVarargsWorkaround : Unsupported major.minor version 52.0
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:307)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:700)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:121)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:100)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:250)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContextInternal(CacheAwareContextLoaderDelegate.java:64)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContext(CacheAwareContextLoaderDelegate.java:91)
	... 25 more
Caused by: org.springframework.beans.factory.CannotLoadBeanClassException: Error loading class [org.apache.spark.api.java.JavaSparkContext] for bean with name 'javaSparkContext' defined in class path resource [spring-mybatis.xml]: problem with class file or dependent class; nested exception is java.lang.UnsupportedClassVersionError: org/apache/spark/api/java/JavaSparkContextVarargsWorkaround : Unsupported major.minor version 52.0
	at org.springframework.beans.factory.support.AbstractBeanFactory.resolveBeanClass(AbstractBeanFactory.java:1330)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.predictBeanType(AbstractAutowireCapableBeanFactory.java:594)
	at org.springframework.beans.factory.support.AbstractBeanFactory.isFactoryBean(AbstractBeanFactory.java:1396)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doGetBeanNamesForType(DefaultListableBeanFactory.java:382)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:361)
	at org.springframework.beans.factory.BeanFactoryUtils.beanNamesForTypeIncludingAncestors(BeanFactoryUtils.java:187)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:999)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:957)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:855)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:441)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	... 41 more
Caused by: java.lang.UnsupportedClassVersionError: org/apache/spark/api/java/JavaSparkContextVarargsWorkaround : Unsupported major.minor version 52.0
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:800)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:449)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:71)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:361)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:800)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:449)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:71)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:361)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	at org.springframework.util.ClassUtils.forName(ClassUtils.java:236)
	at org.springframework.beans.factory.support.AbstractBeanDefinition.resolveBeanClass(AbstractBeanDefinition.java:392)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doResolveBeanClass(AbstractBeanFactory.java:1348)
	at org.springframework.beans.factory.support.AbstractBeanFactory.resolveBeanClass(AbstractBeanFactory.java:1319)
	... 55 more
[INFO] [2018-10-29 22:27:32][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-29 22:27:32][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@3490b317: startup date [Mon Oct 29 22:27:32 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 22:27:32][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-29 22:27:32][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-29 22:27:32][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-29 22:27:33][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-29 22:27:33][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[ERROR] [2018-10-29 22:27:33][org.springframework.test.context.TestContextManager]Caught exception while allowing TestExecutionListener [org.springframework.test.context.support.DependencyInjectionTestExecutionListener@63e0c498] to prepare test instance [com.harleycorp.testmybatis.TestMyBatis@398b0a62]
java.lang.IllegalStateException: Failed to load ApplicationContext
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContext(CacheAwareContextLoaderDelegate.java:99)
	at org.springframework.test.context.DefaultTestContext.getApplicationContext(DefaultTestContext.java:101)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:109)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:75)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:319)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:212)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:232)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:89)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:175)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'testController': Injection of resource dependencies failed; nested exception is org.springframework.beans.factory.CannotLoadBeanClassException: Error loading class [org.apache.spark.api.java.JavaSparkContext] for bean with name 'javaSparkContext' defined in class path resource [spring-mybatis.xml]: problem with class file or dependent class; nested exception is java.lang.UnsupportedClassVersionError: org/apache/spark/api/java/JavaSparkContextVarargsWorkaround : Unsupported major.minor version 52.0
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:307)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:700)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:121)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:100)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:250)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContextInternal(CacheAwareContextLoaderDelegate.java:64)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContext(CacheAwareContextLoaderDelegate.java:91)
	... 25 more
Caused by: org.springframework.beans.factory.CannotLoadBeanClassException: Error loading class [org.apache.spark.api.java.JavaSparkContext] for bean with name 'javaSparkContext' defined in class path resource [spring-mybatis.xml]: problem with class file or dependent class; nested exception is java.lang.UnsupportedClassVersionError: org/apache/spark/api/java/JavaSparkContextVarargsWorkaround : Unsupported major.minor version 52.0
	at org.springframework.beans.factory.support.AbstractBeanFactory.resolveBeanClass(AbstractBeanFactory.java:1330)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.predictBeanType(AbstractAutowireCapableBeanFactory.java:594)
	at org.springframework.beans.factory.support.AbstractBeanFactory.isFactoryBean(AbstractBeanFactory.java:1396)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doGetBeanNamesForType(DefaultListableBeanFactory.java:382)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:361)
	at org.springframework.beans.factory.BeanFactoryUtils.beanNamesForTypeIncludingAncestors(BeanFactoryUtils.java:187)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:999)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:957)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:855)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:441)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	... 41 more
Caused by: java.lang.UnsupportedClassVersionError: org/apache/spark/api/java/JavaSparkContextVarargsWorkaround : Unsupported major.minor version 52.0
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:800)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:449)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:71)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:361)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:800)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:449)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:71)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:361)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	at org.springframework.util.ClassUtils.forName(ClassUtils.java:236)
	at org.springframework.beans.factory.support.AbstractBeanDefinition.resolveBeanClass(AbstractBeanDefinition.java:392)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doResolveBeanClass(AbstractBeanFactory.java:1348)
	at org.springframework.beans.factory.support.AbstractBeanFactory.resolveBeanClass(AbstractBeanFactory.java:1319)
	... 55 more
[INFO] [2018-10-29 22:29:58][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-29 22:29:58][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@5ae50ce6: startup date [Mon Oct 29 22:29:58 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 22:29:58][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-29 22:29:58][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-29 22:29:58][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-29 22:29:58][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-29 22:29:59][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-29 22:30:00][org.apache.spark.SparkContext]Running Spark version 2.2.1
[WARN] [2018-10-29 22:30:00][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR] [2018-10-29 22:30:00][org.apache.hadoop.util.Shell]Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2424)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2424)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2424)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:145)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:159)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:64)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:148)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:125)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:270)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1114)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1017)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:445)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1014)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:957)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:855)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:441)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:700)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:121)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:100)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:250)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContextInternal(CacheAwareContextLoaderDelegate.java:64)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContext(CacheAwareContextLoaderDelegate.java:91)
	at org.springframework.test.context.DefaultTestContext.getApplicationContext(DefaultTestContext.java:101)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:109)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:75)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:319)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:212)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:232)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:89)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:175)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
[INFO] [2018-10-29 22:30:00][org.apache.spark.SparkContext]Submitted application: chiyun
[INFO] [2018-10-29 22:30:00][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-29 22:30:00][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-29 22:30:00][org.apache.spark.SecurityManager]Changing view acls groups to: 
[INFO] [2018-10-29 22:30:00][org.apache.spark.SecurityManager]Changing modify acls groups to: 
[INFO] [2018-10-29 22:30:00][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rym2017); groups with view permissions: Set(); users  with modify permissions: Set(rym2017); groups with modify permissions: Set()
[INFO] [2018-10-29 22:30:01][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 4531.
[INFO] [2018-10-29 22:30:01][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-29 22:30:01][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-29 22:30:01][org.apache.spark.storage.BlockManagerMasterEndpoint]Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] [2018-10-29 22:30:01][org.apache.spark.storage.BlockManagerMasterEndpoint]BlockManagerMasterEndpoint up
[INFO] [2018-10-29 22:30:01][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-c4a179a7-7633-4d41-b407-9a8a9b1e7cbc
[INFO] [2018-10-29 22:30:01][org.apache.spark.storage.memory.MemoryStore]MemoryStore started with capacity 3.0 GB
[INFO] [2018-10-29 22:30:01][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.util.log]Logging initialized @4508ms
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.Server]jetty-9.3.z-SNAPSHOT
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.Server]Started @4617ms
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.AbstractConnector]Started ServerConnector@644d1b61{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[INFO] [2018-10-29 22:30:01][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@5fed9976{/jobs,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@6e8fdd19{/jobs/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@2199e845{/jobs/job,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@2fe2965c{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@40943a6{/stages,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@42679fc2{/stages/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@100aa331{/stages/stage,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@29f3c438{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@5dbbb292{/stages/pool,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@565aa4ac{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@528c8c1{/storage,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@1c046c92{/storage/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@643ba1ed{/storage/rdd,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@26582ca{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@2c3158e0{/environment,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@6f731759{/environment/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@39549f33{/executors,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7a83ccd2{/executors/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@599a9cb2{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@5e1a986c{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@46a795de{/static,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@79957f11{/,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@4b41587d{/api,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@4776e209{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@1f536481{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:01][org.apache.spark.ui.SparkUI]Bound SparkUI to 0.0.0.0, and started at http://192.168.68.1:4040
[INFO] [2018-10-29 22:30:01][org.apache.spark.executor.Executor]Starting executor ID driver on host localhost
[INFO] [2018-10-29 22:30:01][org.apache.spark.util.Utils]Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 4545.
[INFO] [2018-10-29 22:30:01][org.apache.spark.network.netty.NettyBlockTransferService]Server created on 192.168.68.1:4545
[INFO] [2018-10-29 22:30:01][org.apache.spark.storage.BlockManager]Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] [2018-10-29 22:30:01][org.apache.spark.storage.BlockManagerMaster]Registering BlockManager BlockManagerId(driver, 192.168.68.1, 4545, None)
[INFO] [2018-10-29 22:30:01][org.apache.spark.storage.BlockManagerMasterEndpoint]Registering block manager 192.168.68.1:4545 with 3.0 GB RAM, BlockManagerId(driver, 192.168.68.1, 4545, None)
[INFO] [2018-10-29 22:30:01][org.apache.spark.storage.BlockManagerMaster]Registered BlockManager BlockManagerId(driver, 192.168.68.1, 4545, None)
[INFO] [2018-10-29 22:30:01][org.apache.spark.storage.BlockManager]Initialized BlockManager: BlockManagerId(driver, 192.168.68.1, 4545, None)
[INFO] [2018-10-29 22:30:02][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@1282e98{/metrics/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:30:17][com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource]Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 3, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, dataSourceName -> 1hgeebl9y1hc58er160xlt3|3eeb318f, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> com.mysql.jdbc.Driver, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, identityToken -> 1hgeebl9y1hc58er160xlt3|3eeb318f, idleConnectionTestPeriod -> 0, initialPoolSize -> 1, jdbcUrl -> jdbc:mysql://192.168.68.244:3306/myjianshu, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 20, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 1, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, numThreadsAwaitingCheckoutDefaultUser -> 0, preferredTestQuery -> null, properties -> {user=******, password=******}, propertyCycle -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false ]
[INFO] [2018-10-29 22:30:18][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@5ae50ce6: startup date [Mon Oct 29 22:29:58 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 22:30:18][org.apache.spark.SparkContext]Invoking stop() from shutdown hook
[INFO] [2018-10-29 22:30:18][org.apache.spark.SparkContext]SparkContext already stopped.
[INFO] [2018-10-29 22:30:18][org.apache.spark.storage.DiskBlockManager]Shutdown hook called
[INFO] [2018-10-29 22:30:18][org.spark_project.jetty.server.AbstractConnector]Stopped Spark@644d1b61{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[INFO] [2018-10-29 22:30:18][org.apache.spark.util.ShutdownHookManager]Shutdown hook called
[INFO] [2018-10-29 22:30:18][org.apache.spark.ui.SparkUI]Stopped Spark web UI at http://192.168.68.1:4040
[INFO] [2018-10-29 22:30:18][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-e1a572ce-314d-4955-8cfc-3f03fb1e52a0\userFiles-6260c760-9b15-4e98-bb08-bb9bf8e34380
[INFO] [2018-10-29 22:30:18][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-e1a572ce-314d-4955-8cfc-3f03fb1e52a0
[INFO] [2018-10-29 22:30:18][org.apache.spark.MapOutputTrackerMasterEndpoint]MapOutputTrackerMasterEndpoint stopped!
[INFO] [2018-10-29 22:30:18][org.apache.spark.storage.memory.MemoryStore]MemoryStore cleared
[INFO] [2018-10-29 22:30:18][org.apache.spark.storage.BlockManager]BlockManager stopped
[INFO] [2018-10-29 22:30:18][org.apache.spark.storage.BlockManagerMaster]BlockManagerMaster stopped
[INFO] [2018-10-29 22:30:18][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint]OutputCommitCoordinator stopped!
[INFO] [2018-10-29 22:30:18][org.apache.spark.SparkContext]Successfully stopped SparkContext
[INFO] [2018-10-29 22:31:39][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-29 22:31:39][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@20398b7c: startup date [Mon Oct 29 22:31:39 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 22:31:39][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-29 22:31:39][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-29 22:31:39][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-29 22:31:40][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-29 22:31:40][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-29 22:31:41][org.apache.spark.SparkContext]Running Spark version 2.2.1
[WARN] [2018-10-29 22:31:41][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR] [2018-10-29 22:31:41][org.apache.hadoop.util.Shell]Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2424)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2424)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2424)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:145)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:159)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:64)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:148)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:125)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:270)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1114)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1017)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:445)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1014)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:957)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:855)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:441)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:700)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:121)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:100)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:250)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContextInternal(CacheAwareContextLoaderDelegate.java:64)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContext(CacheAwareContextLoaderDelegate.java:91)
	at org.springframework.test.context.DefaultTestContext.getApplicationContext(DefaultTestContext.java:101)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:109)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:75)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:319)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:212)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:232)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:89)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:175)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
[INFO] [2018-10-29 22:31:41][org.apache.spark.SparkContext]Submitted application: chiyun
[INFO] [2018-10-29 22:31:41][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-29 22:31:41][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-29 22:31:41][org.apache.spark.SecurityManager]Changing view acls groups to: 
[INFO] [2018-10-29 22:31:41][org.apache.spark.SecurityManager]Changing modify acls groups to: 
[INFO] [2018-10-29 22:31:41][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rym2017); groups with view permissions: Set(); users  with modify permissions: Set(rym2017); groups with modify permissions: Set()
[INFO] [2018-10-29 22:31:42][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 4664.
[INFO] [2018-10-29 22:31:42][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-29 22:31:42][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-29 22:31:42][org.apache.spark.storage.BlockManagerMasterEndpoint]Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] [2018-10-29 22:31:42][org.apache.spark.storage.BlockManagerMasterEndpoint]BlockManagerMasterEndpoint up
[INFO] [2018-10-29 22:31:42][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-d279030c-598d-49df-995f-938a2a25bd79
[INFO] [2018-10-29 22:31:42][org.apache.spark.storage.memory.MemoryStore]MemoryStore started with capacity 3.0 GB
[INFO] [2018-10-29 22:31:42][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.util.log]Logging initialized @3873ms
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.Server]jetty-9.3.z-SNAPSHOT
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.Server]Started @3953ms
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.AbstractConnector]Started ServerConnector@29528a22{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[INFO] [2018-10-29 22:31:42][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@13f9ad9{/jobs,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@4dbad37{/jobs/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@26a262d6{/jobs/job,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@75798d03{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@1ffcf674{/stages,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7d070ef5{/stages/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@2e2f720{/stages/stage,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@3f93e4a8{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@5445f5ba{/stages/pool,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@342726f1{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@77134e08{/storage,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@67110f71{/storage/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@20749d9{/storage/rdd,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@62628e78{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7c75db8b{/environment,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@3cd206b5{/environment/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@a137d7a{/executors,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@468be356{/executors/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@4df39a88{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@3bec2275{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@60acd609{/static,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@4ad3d266{/,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@15d0849{/api,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@270b6b5e{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7c6189d5{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:42][org.apache.spark.ui.SparkUI]Bound SparkUI to 0.0.0.0, and started at http://192.168.68.1:4040
[INFO] [2018-10-29 22:31:42][org.apache.spark.executor.Executor]Starting executor ID driver on host localhost
[INFO] [2018-10-29 22:31:42][org.apache.spark.util.Utils]Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 4677.
[INFO] [2018-10-29 22:31:42][org.apache.spark.network.netty.NettyBlockTransferService]Server created on 192.168.68.1:4677
[INFO] [2018-10-29 22:31:42][org.apache.spark.storage.BlockManager]Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] [2018-10-29 22:31:42][org.apache.spark.storage.BlockManagerMaster]Registering BlockManager BlockManagerId(driver, 192.168.68.1, 4677, None)
[INFO] [2018-10-29 22:31:42][org.apache.spark.storage.BlockManagerMasterEndpoint]Registering block manager 192.168.68.1:4677 with 3.0 GB RAM, BlockManagerId(driver, 192.168.68.1, 4677, None)
[INFO] [2018-10-29 22:31:42][org.apache.spark.storage.BlockManagerMaster]Registered BlockManager BlockManagerId(driver, 192.168.68.1, 4677, None)
[INFO] [2018-10-29 22:31:42][org.apache.spark.storage.BlockManager]Initialized BlockManager: BlockManagerId(driver, 192.168.68.1, 4677, None)
[INFO] [2018-10-29 22:31:42][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@636bbbbb{/metrics/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:31:43][com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource]Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 3, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, dataSourceName -> 1hgeebl9y1hc7ej3xn8gvy|4a8355dd, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> com.mysql.jdbc.Driver, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, identityToken -> 1hgeebl9y1hc7ej3xn8gvy|4a8355dd, idleConnectionTestPeriod -> 0, initialPoolSize -> 1, jdbcUrl -> jdbc:mysql://192.168.68.244:3306/myjianshu, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 20, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 1, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, numThreadsAwaitingCheckoutDefaultUser -> 0, preferredTestQuery -> null, properties -> {user=******, password=******}, propertyCycle -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false ]
[INFO] [2018-10-29 22:31:44][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@20398b7c: startup date [Mon Oct 29 22:31:39 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 22:31:44][org.apache.spark.SparkContext]Invoking stop() from shutdown hook
[INFO] [2018-10-29 22:31:44][org.apache.spark.SparkContext]SparkContext already stopped.
[INFO] [2018-10-29 22:31:44][org.apache.spark.storage.DiskBlockManager]Shutdown hook called
[INFO] [2018-10-29 22:31:44][org.spark_project.jetty.server.AbstractConnector]Stopped Spark@29528a22{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[INFO] [2018-10-29 22:31:44][org.apache.spark.util.ShutdownHookManager]Shutdown hook called
[INFO] [2018-10-29 22:31:44][org.apache.spark.ui.SparkUI]Stopped Spark web UI at http://192.168.68.1:4040
[INFO] [2018-10-29 22:31:44][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-5ad53d32-ebb0-46ab-b291-2fb4ed80270b\userFiles-f8255928-6076-4fe0-9556-a029ab41e2de
[INFO] [2018-10-29 22:31:44][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-5ad53d32-ebb0-46ab-b291-2fb4ed80270b
[INFO] [2018-10-29 22:31:44][org.apache.spark.MapOutputTrackerMasterEndpoint]MapOutputTrackerMasterEndpoint stopped!
[INFO] [2018-10-29 22:31:44][org.apache.spark.storage.memory.MemoryStore]MemoryStore cleared
[INFO] [2018-10-29 22:31:44][org.apache.spark.storage.BlockManager]BlockManager stopped
[INFO] [2018-10-29 22:31:44][org.apache.spark.storage.BlockManagerMaster]BlockManagerMaster stopped
[INFO] [2018-10-29 22:31:44][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint]OutputCommitCoordinator stopped!
[INFO] [2018-10-29 22:31:44][org.apache.spark.SparkContext]Successfully stopped SparkContext
[INFO] [2018-10-29 22:33:54][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-29 22:33:54][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@20398b7c: startup date [Mon Oct 29 22:33:54 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 22:33:54][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-29 22:33:54][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-29 22:33:54][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-29 22:33:54][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-29 22:33:55][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-29 22:33:56][org.apache.spark.SparkContext]Running Spark version 2.2.1
[WARN] [2018-10-29 22:33:56][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR] [2018-10-29 22:33:56][org.apache.hadoop.util.Shell]Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2424)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2424)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2424)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:145)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:159)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:64)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:148)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:125)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:270)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1114)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1017)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:445)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1014)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:957)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:855)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:441)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:700)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:121)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:100)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:250)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContextInternal(CacheAwareContextLoaderDelegate.java:64)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContext(CacheAwareContextLoaderDelegate.java:91)
	at org.springframework.test.context.DefaultTestContext.getApplicationContext(DefaultTestContext.java:101)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:109)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:75)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:319)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:212)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:232)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:89)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:175)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
[INFO] [2018-10-29 22:33:56][org.apache.spark.SparkContext]Submitted application: chiyun
[INFO] [2018-10-29 22:33:56][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-29 22:33:56][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-29 22:33:56][org.apache.spark.SecurityManager]Changing view acls groups to: 
[INFO] [2018-10-29 22:33:56][org.apache.spark.SecurityManager]Changing modify acls groups to: 
[INFO] [2018-10-29 22:33:56][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rym2017); groups with view permissions: Set(); users  with modify permissions: Set(rym2017); groups with modify permissions: Set()
[INFO] [2018-10-29 22:33:57][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 4825.
[INFO] [2018-10-29 22:33:57][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-29 22:33:57][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-29 22:33:57][org.apache.spark.storage.BlockManagerMasterEndpoint]Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] [2018-10-29 22:33:57][org.apache.spark.storage.BlockManagerMasterEndpoint]BlockManagerMasterEndpoint up
[INFO] [2018-10-29 22:33:57][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-5a7a37b5-b469-47a8-8776-719341751fea
[INFO] [2018-10-29 22:33:57][org.apache.spark.storage.memory.MemoryStore]MemoryStore started with capacity 3.0 GB
[INFO] [2018-10-29 22:33:57][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.util.log]Logging initialized @3958ms
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.Server]jetty-9.3.z-SNAPSHOT
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.Server]Started @4046ms
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.AbstractConnector]Started ServerConnector@1dead5e9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[INFO] [2018-10-29 22:33:57][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@1b7cae6f{/jobs,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7b4acdc2{/jobs/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@11bd803{/jobs/job,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@40f8f5a8{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@442f92e6{/stages,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7a55f148{/stages/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@3ae2ed38{/stages/stage,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@12b5454f{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@1431267b{/stages/pool,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@c808207{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@6a0cbc6f{/storage,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@6f89292e{/storage/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@de77232{/storage/rdd,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@44841b43{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@4ab550d5{/environment,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@58e85c6f{/environment/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@6ac0b715{/executors,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@5c9ac4cc{/executors/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@2264e43c{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@31da3d60{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@65ec8b24{/static,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@3533df16{/,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@4038cd3a{/api,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7e94d093{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@4248e66b{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:57][org.apache.spark.ui.SparkUI]Bound SparkUI to 0.0.0.0, and started at http://192.168.68.1:4040
[INFO] [2018-10-29 22:33:57][org.apache.spark.executor.Executor]Starting executor ID driver on host localhost
[INFO] [2018-10-29 22:33:57][org.apache.spark.util.Utils]Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 4839.
[INFO] [2018-10-29 22:33:57][org.apache.spark.network.netty.NettyBlockTransferService]Server created on 192.168.68.1:4839
[INFO] [2018-10-29 22:33:57][org.apache.spark.storage.BlockManager]Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] [2018-10-29 22:33:57][org.apache.spark.storage.BlockManagerMaster]Registering BlockManager BlockManagerId(driver, 192.168.68.1, 4839, None)
[INFO] [2018-10-29 22:33:57][org.apache.spark.storage.BlockManagerMasterEndpoint]Registering block manager 192.168.68.1:4839 with 3.0 GB RAM, BlockManagerId(driver, 192.168.68.1, 4839, None)
[INFO] [2018-10-29 22:33:57][org.apache.spark.storage.BlockManagerMaster]Registered BlockManager BlockManagerId(driver, 192.168.68.1, 4839, None)
[INFO] [2018-10-29 22:33:57][org.apache.spark.storage.BlockManager]Initialized BlockManager: BlockManagerId(driver, 192.168.68.1, 4839, None)
[INFO] [2018-10-29 22:33:57][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7eae3764{/metrics/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:33:58][com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource]Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 3, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, dataSourceName -> 1hgeebl9y1hcaalz1ddat1s|4a8355dd, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> com.mysql.jdbc.Driver, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, identityToken -> 1hgeebl9y1hcaalz1ddat1s|4a8355dd, idleConnectionTestPeriod -> 0, initialPoolSize -> 1, jdbcUrl -> jdbc:mysql://192.168.68.244:3306/myjianshu, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 20, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 1, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, numThreadsAwaitingCheckoutDefaultUser -> 0, preferredTestQuery -> null, properties -> {user=******, password=******}, propertyCycle -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false ]
[INFO] [2018-10-29 22:33:58][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@20398b7c: startup date [Mon Oct 29 22:33:54 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 22:33:58][org.apache.spark.SparkContext]Invoking stop() from shutdown hook
[INFO] [2018-10-29 22:33:58][org.apache.spark.SparkContext]SparkContext already stopped.
[INFO] [2018-10-29 22:33:58][org.apache.spark.storage.DiskBlockManager]Shutdown hook called
[INFO] [2018-10-29 22:33:58][org.spark_project.jetty.server.AbstractConnector]Stopped Spark@1dead5e9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[INFO] [2018-10-29 22:33:58][org.apache.spark.util.ShutdownHookManager]Shutdown hook called
[INFO] [2018-10-29 22:33:58][org.apache.spark.ui.SparkUI]Stopped Spark web UI at http://192.168.68.1:4040
[INFO] [2018-10-29 22:33:58][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-566fa784-5198-4b42-9431-d72cb06113b5
[INFO] [2018-10-29 22:33:58][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-566fa784-5198-4b42-9431-d72cb06113b5\userFiles-f9f4f55d-b5d3-4d56-85b3-72e7f684d9dd
[INFO] [2018-10-29 22:33:58][org.apache.spark.MapOutputTrackerMasterEndpoint]MapOutputTrackerMasterEndpoint stopped!
[INFO] [2018-10-29 22:33:58][org.apache.spark.storage.memory.MemoryStore]MemoryStore cleared
[INFO] [2018-10-29 22:33:58][org.apache.spark.storage.BlockManager]BlockManager stopped
[INFO] [2018-10-29 22:33:58][org.apache.spark.storage.BlockManagerMaster]BlockManagerMaster stopped
[INFO] [2018-10-29 22:33:58][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint]OutputCommitCoordinator stopped!
[INFO] [2018-10-29 22:33:58][org.apache.spark.SparkContext]Successfully stopped SparkContext
[INFO] [2018-10-29 22:37:56][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-29 22:37:56][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@20398b7c: startup date [Mon Oct 29 22:37:56 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 22:37:56][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-29 22:37:56][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-29 22:37:56][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-29 22:37:56][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-29 22:37:57][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-29 22:37:57][org.apache.spark.SparkContext]Running Spark version 2.2.1
[WARN] [2018-10-29 22:37:58][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR] [2018-10-29 22:37:58][org.apache.hadoop.util.Shell]Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2424)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2424)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2424)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:145)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:159)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:64)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:148)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:125)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:270)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1114)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1017)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:445)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1014)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:957)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:855)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:441)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:700)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:121)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:100)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:250)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContextInternal(CacheAwareContextLoaderDelegate.java:64)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContext(CacheAwareContextLoaderDelegate.java:91)
	at org.springframework.test.context.DefaultTestContext.getApplicationContext(DefaultTestContext.java:101)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:109)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:75)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:319)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:212)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:232)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:89)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:175)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
[INFO] [2018-10-29 22:37:58][org.apache.spark.SparkContext]Submitted application: chiyun
[INFO] [2018-10-29 22:37:58][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-29 22:37:58][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-29 22:37:58][org.apache.spark.SecurityManager]Changing view acls groups to: 
[INFO] [2018-10-29 22:37:58][org.apache.spark.SecurityManager]Changing modify acls groups to: 
[INFO] [2018-10-29 22:37:58][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rym2017); groups with view permissions: Set(); users  with modify permissions: Set(rym2017); groups with modify permissions: Set()
[INFO] [2018-10-29 22:37:59][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 5101.
[INFO] [2018-10-29 22:37:59][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-29 22:37:59][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-29 22:37:59][org.apache.spark.storage.BlockManagerMasterEndpoint]Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] [2018-10-29 22:37:59][org.apache.spark.storage.BlockManagerMasterEndpoint]BlockManagerMasterEndpoint up
[INFO] [2018-10-29 22:37:59][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-17d7d91d-837b-4545-9099-819e54df29c2
[INFO] [2018-10-29 22:37:59][org.apache.spark.storage.memory.MemoryStore]MemoryStore started with capacity 3.0 GB
[INFO] [2018-10-29 22:37:59][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.util.log]Logging initialized @4191ms
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.Server]jetty-9.3.z-SNAPSHOT
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.Server]Started @4275ms
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.AbstractConnector]Started ServerConnector@64e244c1{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[INFO] [2018-10-29 22:37:59][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@21f8e55f{/jobs,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@26a262d6{/jobs/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@58f07f02{/jobs/job,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@1ffcf674{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7d070ef5{/stages,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@2e2f720{/stages/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7f572c37{/stages/stage,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@5445f5ba{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@342726f1{/stages/pool,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@77134e08{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@67110f71{/storage,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@20749d9{/storage/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@62628e78{/storage/rdd,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7c75db8b{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@3cd206b5{/environment,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@a137d7a{/environment/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@468be356{/executors,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@4df39a88{/executors/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@3bec2275{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@60acd609{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@3f49e266{/static,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@15d0849{/,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@14ac77b9{/api,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7c6189d5{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@3e6534e7{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:37:59][org.apache.spark.ui.SparkUI]Bound SparkUI to 0.0.0.0, and started at http://192.168.68.1:4040
[INFO] [2018-10-29 22:37:59][org.apache.spark.executor.Executor]Starting executor ID driver on host localhost
[INFO] [2018-10-29 22:37:59][org.apache.spark.util.Utils]Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 5129.
[INFO] [2018-10-29 22:37:59][org.apache.spark.network.netty.NettyBlockTransferService]Server created on 192.168.68.1:5129
[INFO] [2018-10-29 22:37:59][org.apache.spark.storage.BlockManager]Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] [2018-10-29 22:37:59][org.apache.spark.storage.BlockManagerMaster]Registering BlockManager BlockManagerId(driver, 192.168.68.1, 5129, None)
[INFO] [2018-10-29 22:37:59][org.apache.spark.storage.BlockManagerMasterEndpoint]Registering block manager 192.168.68.1:5129 with 3.0 GB RAM, BlockManagerId(driver, 192.168.68.1, 5129, None)
[INFO] [2018-10-29 22:37:59][org.apache.spark.storage.BlockManagerMaster]Registered BlockManager BlockManagerId(driver, 192.168.68.1, 5129, None)
[INFO] [2018-10-29 22:37:59][org.apache.spark.storage.BlockManager]Initialized BlockManager: BlockManagerId(driver, 192.168.68.1, 5129, None)
[INFO] [2018-10-29 22:37:59][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@10dc7d6{/metrics/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:38:00][com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource]Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 3, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, dataSourceName -> 1hgeebl9y1hcfh7lk9axrg|4a8355dd, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> com.mysql.jdbc.Driver, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, identityToken -> 1hgeebl9y1hcfh7lk9axrg|4a8355dd, idleConnectionTestPeriod -> 0, initialPoolSize -> 1, jdbcUrl -> jdbc:mysql://192.168.68.244:3306/myjianshu, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 20, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 1, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, numThreadsAwaitingCheckoutDefaultUser -> 0, preferredTestQuery -> null, properties -> {user=******, password=******}, propertyCycle -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false ]
[INFO] [2018-10-29 22:38:01][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@20398b7c: startup date [Mon Oct 29 22:37:56 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 22:38:01][org.apache.spark.SparkContext]Invoking stop() from shutdown hook
[INFO] [2018-10-29 22:38:01][org.apache.spark.SparkContext]SparkContext already stopped.
[INFO] [2018-10-29 22:38:01][org.apache.spark.storage.DiskBlockManager]Shutdown hook called
[INFO] [2018-10-29 22:38:01][org.spark_project.jetty.server.AbstractConnector]Stopped Spark@64e244c1{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[INFO] [2018-10-29 22:38:01][org.apache.spark.util.ShutdownHookManager]Shutdown hook called
[INFO] [2018-10-29 22:38:01][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-0f14dae5-b75f-43d2-aa73-187d9ed67f4f
[INFO] [2018-10-29 22:38:01][org.apache.spark.ui.SparkUI]Stopped Spark web UI at http://192.168.68.1:4040
[INFO] [2018-10-29 22:38:01][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-0f14dae5-b75f-43d2-aa73-187d9ed67f4f\userFiles-e2537087-0407-4ef9-8d03-18ac89b33282
[INFO] [2018-10-29 22:38:01][org.apache.spark.MapOutputTrackerMasterEndpoint]MapOutputTrackerMasterEndpoint stopped!
[INFO] [2018-10-29 22:38:01][org.apache.spark.storage.memory.MemoryStore]MemoryStore cleared
[INFO] [2018-10-29 22:38:01][org.apache.spark.storage.BlockManager]BlockManager stopped
[INFO] [2018-10-29 22:38:01][org.apache.spark.storage.BlockManagerMaster]BlockManagerMaster stopped
[INFO] [2018-10-29 22:38:01][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint]OutputCommitCoordinator stopped!
[INFO] [2018-10-29 22:38:01][org.apache.spark.SparkContext]Successfully stopped SparkContext
[INFO] [2018-10-29 22:39:51][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-29 22:39:52][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@5ae50ce6: startup date [Mon Oct 29 22:39:52 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 22:39:52][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-29 22:39:52][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-29 22:39:52][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-29 22:39:52][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-29 22:39:53][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-29 22:39:53][org.apache.spark.SparkContext]Running Spark version 2.2.1
[WARN] [2018-10-29 22:39:54][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR] [2018-10-29 22:39:54][org.apache.hadoop.util.Shell]Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2424)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2424)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2424)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:145)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:159)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:64)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:148)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:125)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:270)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1114)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1017)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:445)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1014)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:957)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:855)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:441)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:700)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:121)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:100)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:250)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContextInternal(CacheAwareContextLoaderDelegate.java:64)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContext(CacheAwareContextLoaderDelegate.java:91)
	at org.springframework.test.context.DefaultTestContext.getApplicationContext(DefaultTestContext.java:101)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:109)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:75)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:319)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:212)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:232)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:89)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:175)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
[INFO] [2018-10-29 22:39:54][org.apache.spark.SparkContext]Submitted application: chiyun
[INFO] [2018-10-29 22:39:54][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-29 22:39:54][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-29 22:39:54][org.apache.spark.SecurityManager]Changing view acls groups to: 
[INFO] [2018-10-29 22:39:54][org.apache.spark.SecurityManager]Changing modify acls groups to: 
[INFO] [2018-10-29 22:39:54][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rym2017); groups with view permissions: Set(); users  with modify permissions: Set(rym2017); groups with modify permissions: Set()
[INFO] [2018-10-29 22:39:55][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 5365.
[INFO] [2018-10-29 22:39:55][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-29 22:39:55][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-29 22:39:55][org.apache.spark.storage.BlockManagerMasterEndpoint]Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] [2018-10-29 22:39:55][org.apache.spark.storage.BlockManagerMasterEndpoint]BlockManagerMasterEndpoint up
[INFO] [2018-10-29 22:39:55][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-9daf6839-aed3-4df5-acb4-4a85071af064
[INFO] [2018-10-29 22:39:55][org.apache.spark.storage.memory.MemoryStore]MemoryStore started with capacity 3.0 GB
[INFO] [2018-10-29 22:39:55][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.util.log]Logging initialized @4571ms
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.Server]jetty-9.3.z-SNAPSHOT
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.Server]Started @4659ms
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.AbstractConnector]Started ServerConnector@678a9516{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[INFO] [2018-10-29 22:39:55][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@6cbb175{/jobs,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@1f10fec6{/jobs/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@30a7653e{/jobs/job,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@382dc417{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@510689af{/stages,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@72ce812e{/stages/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@521441d5{/stages/stage,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@4017fe2c{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@677ce519{/stages/pool,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7cfb0c4c{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@6b63abdc{/storage,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@5f08fe00{/storage/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7c5df615{/storage/rdd,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@377949f1{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@1a21f43f{/environment,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@241fbec{/environment/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@644a3add{/executors,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@4665428b{/executors/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7fd99443{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@6a3fbcb1{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@15d3793b{/static,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@5460edd3{/,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@613f7eb7{/api,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@27960b1e{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@3d3a1903{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:55][org.apache.spark.ui.SparkUI]Bound SparkUI to 0.0.0.0, and started at http://192.168.68.1:4040
[INFO] [2018-10-29 22:39:55][org.apache.spark.executor.Executor]Starting executor ID driver on host localhost
[INFO] [2018-10-29 22:39:55][org.apache.spark.util.Utils]Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 5379.
[INFO] [2018-10-29 22:39:55][org.apache.spark.network.netty.NettyBlockTransferService]Server created on 192.168.68.1:5379
[INFO] [2018-10-29 22:39:55][org.apache.spark.storage.BlockManager]Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] [2018-10-29 22:39:55][org.apache.spark.storage.BlockManagerMaster]Registering BlockManager BlockManagerId(driver, 192.168.68.1, 5379, None)
[INFO] [2018-10-29 22:39:55][org.apache.spark.storage.BlockManagerMasterEndpoint]Registering block manager 192.168.68.1:5379 with 3.0 GB RAM, BlockManagerId(driver, 192.168.68.1, 5379, None)
[INFO] [2018-10-29 22:39:55][org.apache.spark.storage.BlockManagerMaster]Registered BlockManager BlockManagerId(driver, 192.168.68.1, 5379, None)
[INFO] [2018-10-29 22:39:55][org.apache.spark.storage.BlockManager]Initialized BlockManager: BlockManagerId(driver, 192.168.68.1, 5379, None)
[INFO] [2018-10-29 22:39:56][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@1d91fa02{/metrics/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:39:56][com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource]Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 3, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, dataSourceName -> 1hgeebl9y1hchyp31fprxh1|3eeb318f, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> com.mysql.jdbc.Driver, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, identityToken -> 1hgeebl9y1hchyp31fprxh1|3eeb318f, idleConnectionTestPeriod -> 0, initialPoolSize -> 1, jdbcUrl -> jdbc:mysql://192.168.68.244:3306/myjianshu, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 20, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 1, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, numThreadsAwaitingCheckoutDefaultUser -> 0, preferredTestQuery -> null, properties -> {user=******, password=******}, propertyCycle -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false ]
[INFO] [2018-10-29 22:39:56][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@5ae50ce6: startup date [Mon Oct 29 22:39:52 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 22:39:56][org.apache.spark.SparkContext]Invoking stop() from shutdown hook
[INFO] [2018-10-29 22:39:56][org.apache.spark.SparkContext]SparkContext already stopped.
[INFO] [2018-10-29 22:39:56][org.apache.spark.storage.DiskBlockManager]Shutdown hook called
[INFO] [2018-10-29 22:39:56][org.spark_project.jetty.server.AbstractConnector]Stopped Spark@678a9516{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[INFO] [2018-10-29 22:39:56][org.apache.spark.util.ShutdownHookManager]Shutdown hook called
[INFO] [2018-10-29 22:39:56][org.apache.spark.ui.SparkUI]Stopped Spark web UI at http://192.168.68.1:4040
[INFO] [2018-10-29 22:39:56][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-86b83d58-11db-481a-957e-bd269825294c
[INFO] [2018-10-29 22:39:56][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-86b83d58-11db-481a-957e-bd269825294c\userFiles-dc7a019d-309d-4b49-b7e8-7e76f432d1b4
[INFO] [2018-10-29 22:39:56][org.apache.spark.MapOutputTrackerMasterEndpoint]MapOutputTrackerMasterEndpoint stopped!
[INFO] [2018-10-29 22:39:56][org.apache.spark.storage.memory.MemoryStore]MemoryStore cleared
[INFO] [2018-10-29 22:39:56][org.apache.spark.storage.BlockManager]BlockManager stopped
[INFO] [2018-10-29 22:39:56][org.apache.spark.storage.BlockManagerMaster]BlockManagerMaster stopped
[INFO] [2018-10-29 22:39:56][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint]OutputCommitCoordinator stopped!
[INFO] [2018-10-29 22:39:56][org.apache.spark.SparkContext]Successfully stopped SparkContext
[INFO] [2018-10-29 22:42:37][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-29 22:42:37][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@20398b7c: startup date [Mon Oct 29 22:42:37 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 22:42:37][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-29 22:42:37][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-29 22:42:37][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-29 22:42:37][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-29 22:42:38][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-29 22:42:38][org.apache.spark.SparkContext]Running Spark version 2.2.1
[WARN] [2018-10-29 22:42:39][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR] [2018-10-29 22:42:39][org.apache.hadoop.util.Shell]Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2424)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2424)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2424)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:145)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:159)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:64)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:148)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:125)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:270)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1114)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1017)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:445)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1014)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:957)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:855)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:441)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:700)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:121)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:100)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:250)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContextInternal(CacheAwareContextLoaderDelegate.java:64)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContext(CacheAwareContextLoaderDelegate.java:91)
	at org.springframework.test.context.DefaultTestContext.getApplicationContext(DefaultTestContext.java:101)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:109)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:75)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:319)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:212)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:232)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:89)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:175)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
[INFO] [2018-10-29 22:42:39][org.apache.spark.SparkContext]Submitted application: chiyun
[INFO] [2018-10-29 22:42:39][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-29 22:42:39][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-29 22:42:39][org.apache.spark.SecurityManager]Changing view acls groups to: 
[INFO] [2018-10-29 22:42:39][org.apache.spark.SecurityManager]Changing modify acls groups to: 
[INFO] [2018-10-29 22:42:39][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rym2017); groups with view permissions: Set(); users  with modify permissions: Set(rym2017); groups with modify permissions: Set()
[INFO] [2018-10-29 22:42:40][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 5550.
[INFO] [2018-10-29 22:42:40][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-29 22:42:40][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-29 22:42:40][org.apache.spark.storage.BlockManagerMasterEndpoint]Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] [2018-10-29 22:42:40][org.apache.spark.storage.BlockManagerMasterEndpoint]BlockManagerMasterEndpoint up
[INFO] [2018-10-29 22:42:40][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-abfc0c6e-30ba-49e7-9182-e9f7584ddd67
[INFO] [2018-10-29 22:42:40][org.apache.spark.storage.memory.MemoryStore]MemoryStore started with capacity 3.0 GB
[INFO] [2018-10-29 22:42:40][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.util.log]Logging initialized @3902ms
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.Server]jetty-9.3.z-SNAPSHOT
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.Server]Started @3978ms
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.AbstractConnector]Started ServerConnector@29528a22{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[INFO] [2018-10-29 22:42:40][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@13f9ad9{/jobs,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@4dbad37{/jobs/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@26a262d6{/jobs/job,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@75798d03{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@1ffcf674{/stages,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7d070ef5{/stages/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@2e2f720{/stages/stage,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@3f93e4a8{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@5445f5ba{/stages/pool,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@342726f1{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@77134e08{/storage,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@67110f71{/storage/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@20749d9{/storage/rdd,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@62628e78{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7c75db8b{/environment,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@3cd206b5{/environment/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@a137d7a{/executors,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@468be356{/executors/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@4df39a88{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@3bec2275{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@60acd609{/static,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@4ad3d266{/,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@15d0849{/api,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@270b6b5e{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7c6189d5{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][org.apache.spark.ui.SparkUI]Bound SparkUI to 0.0.0.0, and started at http://192.168.68.1:4040
[INFO] [2018-10-29 22:42:40][org.apache.spark.executor.Executor]Starting executor ID driver on host localhost
[INFO] [2018-10-29 22:42:40][org.apache.spark.util.Utils]Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 5563.
[INFO] [2018-10-29 22:42:40][org.apache.spark.network.netty.NettyBlockTransferService]Server created on 192.168.68.1:5563
[INFO] [2018-10-29 22:42:40][org.apache.spark.storage.BlockManager]Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] [2018-10-29 22:42:40][org.apache.spark.storage.BlockManagerMaster]Registering BlockManager BlockManagerId(driver, 192.168.68.1, 5563, None)
[INFO] [2018-10-29 22:42:40][org.apache.spark.storage.BlockManagerMasterEndpoint]Registering block manager 192.168.68.1:5563 with 3.0 GB RAM, BlockManagerId(driver, 192.168.68.1, 5563, None)
[INFO] [2018-10-29 22:42:40][org.apache.spark.storage.BlockManagerMaster]Registered BlockManager BlockManagerId(driver, 192.168.68.1, 5563, None)
[INFO] [2018-10-29 22:42:40][org.apache.spark.storage.BlockManager]Initialized BlockManager: BlockManagerId(driver, 192.168.68.1, 5563, None)
[INFO] [2018-10-29 22:42:40][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@636bbbbb{/metrics/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:42:40][com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource]Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 3, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, dataSourceName -> 1hgeebl9y1hcli4f1rqd60h|4a8355dd, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> com.mysql.jdbc.Driver, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, identityToken -> 1hgeebl9y1hcli4f1rqd60h|4a8355dd, idleConnectionTestPeriod -> 0, initialPoolSize -> 1, jdbcUrl -> jdbc:mysql://192.168.68.244:3306/myjianshu, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 20, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 1, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, numThreadsAwaitingCheckoutDefaultUser -> 0, preferredTestQuery -> null, properties -> {user=******, password=******}, propertyCycle -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false ]
[INFO] [2018-10-29 22:42:41][org.apache.spark.SparkContext]Starting job: first at SparkUpperServiceImpl.java:230
[INFO] [2018-10-29 22:42:41][org.apache.spark.scheduler.DAGScheduler]Got job 0 (first at SparkUpperServiceImpl.java:230) with 1 output partitions
[INFO] [2018-10-29 22:42:41][org.apache.spark.scheduler.DAGScheduler]Final stage: ResultStage 0 (first at SparkUpperServiceImpl.java:230)
[INFO] [2018-10-29 22:42:41][org.apache.spark.scheduler.DAGScheduler]Parents of final stage: List()
[INFO] [2018-10-29 22:42:41][org.apache.spark.scheduler.DAGScheduler]Missing parents: List()
[INFO] [2018-10-29 22:42:41][org.apache.spark.scheduler.DAGScheduler]Submitting ResultStage 0 (ParallelCollectionRDD[0] at parallelize at SparkUpperServiceImpl.java:229), which has no missing parents
[INFO] [2018-10-29 22:42:41][org.apache.spark.storage.memory.MemoryStore]Block broadcast_0 stored as values in memory (estimated size 1648.0 B, free 3.0 GB)
[INFO] [2018-10-29 22:42:41][org.apache.spark.storage.memory.MemoryStore]Block broadcast_0_piece0 stored as bytes in memory (estimated size 1105.0 B, free 3.0 GB)
[INFO] [2018-10-29 22:42:41][org.apache.spark.storage.BlockManagerInfo]Added broadcast_0_piece0 in memory on 192.168.68.1:5563 (size: 1105.0 B, free: 3.0 GB)
[INFO] [2018-10-29 22:42:41][org.apache.spark.SparkContext]Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO] [2018-10-29 22:42:41][org.apache.spark.scheduler.DAGScheduler]Submitting 1 missing tasks from ResultStage 0 (ParallelCollectionRDD[0] at parallelize at SparkUpperServiceImpl.java:229) (first 15 tasks are for partitions Vector(0))
[INFO] [2018-10-29 22:42:41][org.apache.spark.scheduler.TaskSchedulerImpl]Adding task set 0.0 with 1 tasks
[INFO] [2018-10-29 22:42:41][org.apache.spark.scheduler.TaskSetManager]Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4881 bytes)
[INFO] [2018-10-29 22:42:41][org.apache.spark.executor.Executor]Running task 0.0 in stage 0.0 (TID 0)
[INFO] [2018-10-29 22:42:42][org.apache.spark.executor.Executor]Finished task 0.0 in stage 0.0 (TID 0). 683 bytes result sent to driver
[INFO] [2018-10-29 22:42:42][org.apache.spark.scheduler.TaskSetManager]Finished task 0.0 in stage 0.0 (TID 0) in 89 ms on localhost (executor driver) (1/1)
[INFO] [2018-10-29 22:42:42][org.apache.spark.scheduler.TaskSchedulerImpl]Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] [2018-10-29 22:42:42][org.apache.spark.scheduler.DAGScheduler]ResultStage 0 (first at SparkUpperServiceImpl.java:230) finished in 0.113 s
[INFO] [2018-10-29 22:42:42][org.apache.spark.scheduler.DAGScheduler]Job 0 finished: first at SparkUpperServiceImpl.java:230, took 0.311527 s
[INFO] [2018-10-29 22:42:42][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@20398b7c: startup date [Mon Oct 29 22:42:37 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 22:42:42][org.apache.spark.SparkContext]Invoking stop() from shutdown hook
[INFO] [2018-10-29 22:42:42][org.apache.spark.SparkContext]SparkContext already stopped.
[INFO] [2018-10-29 22:42:42][org.apache.spark.storage.DiskBlockManager]Shutdown hook called
[INFO] [2018-10-29 22:42:42][org.apache.spark.storage.BlockManagerInfo]Removed broadcast_0_piece0 on 192.168.68.1:5563 in memory (size: 1105.0 B, free: 3.0 GB)
[INFO] [2018-10-29 22:42:42][org.spark_project.jetty.server.AbstractConnector]Stopped Spark@29528a22{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[INFO] [2018-10-29 22:42:42][org.apache.spark.ui.SparkUI]Stopped Spark web UI at http://192.168.68.1:4040
[INFO] [2018-10-29 22:42:42][org.apache.spark.util.ShutdownHookManager]Shutdown hook called
[INFO] [2018-10-29 22:42:42][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-e8b59c29-aa30-4e28-b511-0b0403eb3d06
[INFO] [2018-10-29 22:42:42][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-e8b59c29-aa30-4e28-b511-0b0403eb3d06\userFiles-9e6b1793-0857-4d4a-bc8c-8df4c9962d5e
[INFO] [2018-10-29 22:42:42][org.apache.spark.MapOutputTrackerMasterEndpoint]MapOutputTrackerMasterEndpoint stopped!
[INFO] [2018-10-29 22:42:42][org.apache.spark.storage.memory.MemoryStore]MemoryStore cleared
[INFO] [2018-10-29 22:42:42][org.apache.spark.storage.BlockManager]BlockManager stopped
[INFO] [2018-10-29 22:42:42][org.apache.spark.storage.BlockManagerMaster]BlockManagerMaster stopped
[INFO] [2018-10-29 22:42:42][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint]OutputCommitCoordinator stopped!
[INFO] [2018-10-29 22:42:42][org.apache.spark.SparkContext]Successfully stopped SparkContext
[INFO] [2018-10-29 22:43:45][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-29 22:43:45][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@20398b7c: startup date [Mon Oct 29 22:43:45 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 22:43:45][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-29 22:43:45][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-29 22:43:45][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-29 22:43:46][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-29 22:43:46][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-29 22:43:47][org.apache.spark.SparkContext]Running Spark version 2.2.1
[WARN] [2018-10-29 22:43:47][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR] [2018-10-29 22:43:47][org.apache.hadoop.util.Shell]Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2424)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2424)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2424)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:145)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:159)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:64)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:148)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:125)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:270)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1114)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1017)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:445)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1014)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:957)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:855)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:441)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:700)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:121)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:100)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:250)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContextInternal(CacheAwareContextLoaderDelegate.java:64)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContext(CacheAwareContextLoaderDelegate.java:91)
	at org.springframework.test.context.DefaultTestContext.getApplicationContext(DefaultTestContext.java:101)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:109)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:75)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:319)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:212)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:232)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:89)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:175)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
[INFO] [2018-10-29 22:43:47][org.apache.spark.SparkContext]Submitted application: chiyun
[INFO] [2018-10-29 22:43:47][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-29 22:43:47][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-29 22:43:47][org.apache.spark.SecurityManager]Changing view acls groups to: 
[INFO] [2018-10-29 22:43:47][org.apache.spark.SecurityManager]Changing modify acls groups to: 
[INFO] [2018-10-29 22:43:47][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rym2017); groups with view permissions: Set(); users  with modify permissions: Set(rym2017); groups with modify permissions: Set()
[INFO] [2018-10-29 22:43:48][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 5659.
[INFO] [2018-10-29 22:43:48][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-29 22:43:48][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-29 22:43:48][org.apache.spark.storage.BlockManagerMasterEndpoint]Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] [2018-10-29 22:43:48][org.apache.spark.storage.BlockManagerMasterEndpoint]BlockManagerMasterEndpoint up
[INFO] [2018-10-29 22:43:48][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-f60c763e-e942-4923-a180-0122ec1bd9a9
[INFO] [2018-10-29 22:43:48][org.apache.spark.storage.memory.MemoryStore]MemoryStore started with capacity 3.0 GB
[INFO] [2018-10-29 22:43:48][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.util.log]Logging initialized @4079ms
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.Server]jetty-9.3.z-SNAPSHOT
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.Server]Started @4152ms
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.AbstractConnector]Started ServerConnector@602d3e94{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[INFO] [2018-10-29 22:43:48][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@4f4c789f{/jobs,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@5edf2821{/jobs/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7b4acdc2{/jobs/job,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@58f07f02{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@40f8f5a8{/stages,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@442f92e6{/stages/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7a55f148{/stages/stage,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@2add4d24{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@12b5454f{/stages/pool,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@1431267b{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@c808207{/storage,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@6a0cbc6f{/storage/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@6f89292e{/storage/rdd,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@de77232{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@44841b43{/environment,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@4ab550d5{/environment/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@58e85c6f{/executors,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@6ac0b715{/executors/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@5c9ac4cc{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@2264e43c{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@31da3d60{/static,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@ce9b9a9{/,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@3533df16{/api,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@506dcf55{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7e94d093{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:48][org.apache.spark.ui.SparkUI]Bound SparkUI to 0.0.0.0, and started at http://192.168.68.1:4040
[INFO] [2018-10-29 22:43:48][org.apache.spark.executor.Executor]Starting executor ID driver on host localhost
[INFO] [2018-10-29 22:43:48][org.apache.spark.util.Utils]Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 5676.
[INFO] [2018-10-29 22:43:48][org.apache.spark.network.netty.NettyBlockTransferService]Server created on 192.168.68.1:5676
[INFO] [2018-10-29 22:43:48][org.apache.spark.storage.BlockManager]Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] [2018-10-29 22:43:48][org.apache.spark.storage.BlockManagerMaster]Registering BlockManager BlockManagerId(driver, 192.168.68.1, 5676, None)
[INFO] [2018-10-29 22:43:48][org.apache.spark.storage.BlockManagerMasterEndpoint]Registering block manager 192.168.68.1:5676 with 3.0 GB RAM, BlockManagerId(driver, 192.168.68.1, 5676, None)
[INFO] [2018-10-29 22:43:48][org.apache.spark.storage.BlockManagerMaster]Registered BlockManager BlockManagerId(driver, 192.168.68.1, 5676, None)
[INFO] [2018-10-29 22:43:48][org.apache.spark.storage.BlockManager]Initialized BlockManager: BlockManagerId(driver, 192.168.68.1, 5676, None)
[INFO] [2018-10-29 22:43:49][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@d0865a3{/metrics/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:43:49][com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource]Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 3, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, dataSourceName -> 1hgeebl9y1hcmyq7tb96ft|4a8355dd, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> com.mysql.jdbc.Driver, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, identityToken -> 1hgeebl9y1hcmyq7tb96ft|4a8355dd, idleConnectionTestPeriod -> 0, initialPoolSize -> 1, jdbcUrl -> jdbc:mysql://192.168.68.244:3306/myjianshu, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 20, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 1, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, numThreadsAwaitingCheckoutDefaultUser -> 0, preferredTestQuery -> null, properties -> {user=******, password=******}, propertyCycle -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false ]
[INFO] [2018-10-29 22:43:50][org.apache.spark.SparkContext]Starting job: first at SparkUpperServiceImpl.java:230
[INFO] [2018-10-29 22:43:50][org.apache.spark.scheduler.DAGScheduler]Got job 0 (first at SparkUpperServiceImpl.java:230) with 1 output partitions
[INFO] [2018-10-29 22:43:50][org.apache.spark.scheduler.DAGScheduler]Final stage: ResultStage 0 (first at SparkUpperServiceImpl.java:230)
[INFO] [2018-10-29 22:43:50][org.apache.spark.scheduler.DAGScheduler]Parents of final stage: List()
[INFO] [2018-10-29 22:43:50][org.apache.spark.scheduler.DAGScheduler]Missing parents: List()
[INFO] [2018-10-29 22:43:50][org.apache.spark.scheduler.DAGScheduler]Submitting ResultStage 0 (ParallelCollectionRDD[0] at parallelize at SparkUpperServiceImpl.java:229), which has no missing parents
[INFO] [2018-10-29 22:43:50][org.apache.spark.storage.memory.MemoryStore]Block broadcast_0 stored as values in memory (estimated size 1648.0 B, free 3.0 GB)
[INFO] [2018-10-29 22:43:50][org.apache.spark.storage.memory.MemoryStore]Block broadcast_0_piece0 stored as bytes in memory (estimated size 1105.0 B, free 3.0 GB)
[INFO] [2018-10-29 22:43:50][org.apache.spark.storage.BlockManagerInfo]Added broadcast_0_piece0 in memory on 192.168.68.1:5676 (size: 1105.0 B, free: 3.0 GB)
[INFO] [2018-10-29 22:43:50][org.apache.spark.SparkContext]Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO] [2018-10-29 22:43:50][org.apache.spark.scheduler.DAGScheduler]Submitting 1 missing tasks from ResultStage 0 (ParallelCollectionRDD[0] at parallelize at SparkUpperServiceImpl.java:229) (first 15 tasks are for partitions Vector(0))
[INFO] [2018-10-29 22:43:50][org.apache.spark.scheduler.TaskSchedulerImpl]Adding task set 0.0 with 1 tasks
[INFO] [2018-10-29 22:43:50][org.apache.spark.scheduler.TaskSetManager]Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4881 bytes)
[INFO] [2018-10-29 22:43:50][org.apache.spark.executor.Executor]Running task 0.0 in stage 0.0 (TID 0)
[INFO] [2018-10-29 22:43:50][org.apache.spark.executor.Executor]Finished task 0.0 in stage 0.0 (TID 0). 726 bytes result sent to driver
[INFO] [2018-10-29 22:43:50][org.apache.spark.scheduler.TaskSetManager]Finished task 0.0 in stage 0.0 (TID 0) in 86 ms on localhost (executor driver) (1/1)
[INFO] [2018-10-29 22:43:50][org.apache.spark.scheduler.TaskSchedulerImpl]Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] [2018-10-29 22:43:50][org.apache.spark.scheduler.DAGScheduler]ResultStage 0 (first at SparkUpperServiceImpl.java:230) finished in 0.122 s
[INFO] [2018-10-29 22:43:50][org.apache.spark.scheduler.DAGScheduler]Job 0 finished: first at SparkUpperServiceImpl.java:230, took 0.314845 s
[INFO] [2018-10-29 22:43:50][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@20398b7c: startup date [Mon Oct 29 22:43:45 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 22:43:50][org.apache.spark.SparkContext]Invoking stop() from shutdown hook
[INFO] [2018-10-29 22:43:50][org.apache.spark.SparkContext]SparkContext already stopped.
[INFO] [2018-10-29 22:43:50][org.apache.spark.storage.DiskBlockManager]Shutdown hook called
[INFO] [2018-10-29 22:43:50][org.spark_project.jetty.server.AbstractConnector]Stopped Spark@602d3e94{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[INFO] [2018-10-29 22:43:50][org.apache.spark.ui.SparkUI]Stopped Spark web UI at http://192.168.68.1:4040
[INFO] [2018-10-29 22:43:50][org.apache.spark.util.ShutdownHookManager]Shutdown hook called
[INFO] [2018-10-29 22:43:50][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-92408efc-7d3f-4277-a56f-e46a91ac16a8
[INFO] [2018-10-29 22:43:50][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-92408efc-7d3f-4277-a56f-e46a91ac16a8\userFiles-1ae43b27-c7df-4c02-8dbc-b362a10ca2f3
[INFO] [2018-10-29 22:43:50][org.apache.spark.MapOutputTrackerMasterEndpoint]MapOutputTrackerMasterEndpoint stopped!
[INFO] [2018-10-29 22:43:50][org.apache.spark.storage.memory.MemoryStore]MemoryStore cleared
[INFO] [2018-10-29 22:43:50][org.apache.spark.storage.BlockManager]BlockManager stopped
[INFO] [2018-10-29 22:43:50][org.apache.spark.storage.BlockManagerMaster]BlockManagerMaster stopped
[INFO] [2018-10-29 22:43:50][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint]OutputCommitCoordinator stopped!
[INFO] [2018-10-29 22:43:50][org.apache.spark.SparkContext]Successfully stopped SparkContext
[INFO] [2018-10-29 22:46:45][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-29 22:46:45][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@20398b7c: startup date [Mon Oct 29 22:46:45 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 22:46:45][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-29 22:46:45][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-29 22:46:45][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-29 22:46:46][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-29 22:46:46][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-29 22:46:47][org.apache.spark.SparkContext]Running Spark version 2.2.1
[WARN] [2018-10-29 22:46:47][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR] [2018-10-29 22:46:47][org.apache.hadoop.util.Shell]Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2424)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2424)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2424)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:145)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:159)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:64)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:148)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:125)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:270)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1114)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1017)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:445)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1014)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:957)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:855)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:441)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:700)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:121)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:100)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:250)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContextInternal(CacheAwareContextLoaderDelegate.java:64)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContext(CacheAwareContextLoaderDelegate.java:91)
	at org.springframework.test.context.DefaultTestContext.getApplicationContext(DefaultTestContext.java:101)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:109)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:75)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:319)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:212)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:232)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:89)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:175)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
[INFO] [2018-10-29 22:46:47][org.apache.spark.SparkContext]Submitted application: chiyun
[INFO] [2018-10-29 22:46:47][org.apache.spark.SecurityManager]Changing view acls to: rym2017
[INFO] [2018-10-29 22:46:47][org.apache.spark.SecurityManager]Changing modify acls to: rym2017
[INFO] [2018-10-29 22:46:47][org.apache.spark.SecurityManager]Changing view acls groups to: 
[INFO] [2018-10-29 22:46:47][org.apache.spark.SecurityManager]Changing modify acls groups to: 
[INFO] [2018-10-29 22:46:47][org.apache.spark.SecurityManager]SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rym2017); groups with view permissions: Set(); users  with modify permissions: Set(rym2017); groups with modify permissions: Set()
[INFO] [2018-10-29 22:46:48][org.apache.spark.util.Utils]Successfully started service 'sparkDriver' on port 5868.
[INFO] [2018-10-29 22:46:48][org.apache.spark.SparkEnv]Registering MapOutputTracker
[INFO] [2018-10-29 22:46:48][org.apache.spark.SparkEnv]Registering BlockManagerMaster
[INFO] [2018-10-29 22:46:48][org.apache.spark.storage.BlockManagerMasterEndpoint]Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] [2018-10-29 22:46:48][org.apache.spark.storage.BlockManagerMasterEndpoint]BlockManagerMasterEndpoint up
[INFO] [2018-10-29 22:46:48][org.apache.spark.storage.DiskBlockManager]Created local directory at C:\Users\20474\AppData\Local\Temp\blockmgr-d1fbec5e-a648-4c95-ae8b-ee1eb66f053b
[INFO] [2018-10-29 22:46:48][org.apache.spark.storage.memory.MemoryStore]MemoryStore started with capacity 3.0 GB
[INFO] [2018-10-29 22:46:48][org.apache.spark.SparkEnv]Registering OutputCommitCoordinator
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.util.log]Logging initialized @3999ms
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.Server]jetty-9.3.z-SNAPSHOT
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.Server]Started @4077ms
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.AbstractConnector]Started ServerConnector@1ceac56b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[INFO] [2018-10-29 22:46:48][org.apache.spark.util.Utils]Successfully started service 'SparkUI' on port 4040.
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@13f9ad9{/jobs,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@4dbad37{/jobs/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@26a262d6{/jobs/job,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@75798d03{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@1ffcf674{/stages,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7d070ef5{/stages/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@2e2f720{/stages/stage,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@3f93e4a8{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@5445f5ba{/stages/pool,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@342726f1{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@77134e08{/storage,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@67110f71{/storage/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@20749d9{/storage/rdd,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@62628e78{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7c75db8b{/environment,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@3cd206b5{/environment/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@a137d7a{/executors,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@468be356{/executors/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@4df39a88{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@3bec2275{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@60acd609{/static,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@4ad3d266{/,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@15d0849{/api,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@270b6b5e{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@7c6189d5{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:48][org.apache.spark.ui.SparkUI]Bound SparkUI to 0.0.0.0, and started at http://192.168.68.1:4040
[INFO] [2018-10-29 22:46:48][org.apache.spark.executor.Executor]Starting executor ID driver on host localhost
[INFO] [2018-10-29 22:46:48][org.apache.spark.util.Utils]Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 5881.
[INFO] [2018-10-29 22:46:48][org.apache.spark.network.netty.NettyBlockTransferService]Server created on 192.168.68.1:5881
[INFO] [2018-10-29 22:46:48][org.apache.spark.storage.BlockManager]Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] [2018-10-29 22:46:48][org.apache.spark.storage.BlockManagerMaster]Registering BlockManager BlockManagerId(driver, 192.168.68.1, 5881, None)
[INFO] [2018-10-29 22:46:48][org.apache.spark.storage.BlockManagerMasterEndpoint]Registering block manager 192.168.68.1:5881 with 3.0 GB RAM, BlockManagerId(driver, 192.168.68.1, 5881, None)
[INFO] [2018-10-29 22:46:48][org.apache.spark.storage.BlockManagerMaster]Registered BlockManager BlockManagerId(driver, 192.168.68.1, 5881, None)
[INFO] [2018-10-29 22:46:48][org.apache.spark.storage.BlockManager]Initialized BlockManager: BlockManagerId(driver, 192.168.68.1, 5881, None)
[INFO] [2018-10-29 22:46:48][org.spark_project.jetty.server.handler.ContextHandler]Started o.s.j.s.ServletContextHandler@636bbbbb{/metrics/json,null,AVAILABLE,@Spark}
[INFO] [2018-10-29 22:46:49][com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource]Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 3, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, dataSourceName -> 1hgeebl9y1hcqtkm1yhwrjb|4a8355dd, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> com.mysql.jdbc.Driver, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, identityToken -> 1hgeebl9y1hcqtkm1yhwrjb|4a8355dd, idleConnectionTestPeriod -> 0, initialPoolSize -> 1, jdbcUrl -> jdbc:mysql://192.168.68.244:3306/myjianshu, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 20, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 1, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, numThreadsAwaitingCheckoutDefaultUser -> 0, preferredTestQuery -> null, properties -> {user=******, password=******}, propertyCycle -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false ]
[INFO] [2018-10-29 22:46:50][org.apache.spark.SparkContext]Starting job: first at SparkUpperServiceImpl.java:231
[INFO] [2018-10-29 22:46:50][org.apache.spark.scheduler.DAGScheduler]Got job 0 (first at SparkUpperServiceImpl.java:231) with 1 output partitions
[INFO] [2018-10-29 22:46:50][org.apache.spark.scheduler.DAGScheduler]Final stage: ResultStage 0 (first at SparkUpperServiceImpl.java:231)
[INFO] [2018-10-29 22:46:50][org.apache.spark.scheduler.DAGScheduler]Parents of final stage: List()
[INFO] [2018-10-29 22:46:50][org.apache.spark.scheduler.DAGScheduler]Missing parents: List()
[INFO] [2018-10-29 22:46:50][org.apache.spark.scheduler.DAGScheduler]Submitting ResultStage 0 (ParallelCollectionRDD[0] at parallelize at SparkUpperServiceImpl.java:230), which has no missing parents
[INFO] [2018-10-29 22:46:50][org.apache.spark.storage.memory.MemoryStore]Block broadcast_0 stored as values in memory (estimated size 1648.0 B, free 3.0 GB)
[INFO] [2018-10-29 22:46:50][org.apache.spark.storage.memory.MemoryStore]Block broadcast_0_piece0 stored as bytes in memory (estimated size 1105.0 B, free 3.0 GB)
[INFO] [2018-10-29 22:46:50][org.apache.spark.storage.BlockManagerInfo]Added broadcast_0_piece0 in memory on 192.168.68.1:5881 (size: 1105.0 B, free: 3.0 GB)
[INFO] [2018-10-29 22:46:50][org.apache.spark.SparkContext]Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO] [2018-10-29 22:46:50][org.apache.spark.scheduler.DAGScheduler]Submitting 1 missing tasks from ResultStage 0 (ParallelCollectionRDD[0] at parallelize at SparkUpperServiceImpl.java:230) (first 15 tasks are for partitions Vector(0))
[INFO] [2018-10-29 22:46:50][org.apache.spark.scheduler.TaskSchedulerImpl]Adding task set 0.0 with 1 tasks
[INFO] [2018-10-29 22:46:50][org.apache.spark.scheduler.TaskSetManager]Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4881 bytes)
[INFO] [2018-10-29 22:46:50][org.apache.spark.executor.Executor]Running task 0.0 in stage 0.0 (TID 0)
[INFO] [2018-10-29 22:46:51][org.apache.spark.executor.Executor]Finished task 0.0 in stage 0.0 (TID 0). 769 bytes result sent to driver
[INFO] [2018-10-29 22:46:51][org.apache.spark.scheduler.TaskSetManager]Finished task 0.0 in stage 0.0 (TID 0) in 81 ms on localhost (executor driver) (1/1)
[INFO] [2018-10-29 22:46:51][org.apache.spark.scheduler.TaskSchedulerImpl]Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] [2018-10-29 22:46:51][org.apache.spark.scheduler.DAGScheduler]ResultStage 0 (first at SparkUpperServiceImpl.java:231) finished in 0.118 s
[INFO] [2018-10-29 22:46:51][org.apache.spark.scheduler.DAGScheduler]Job 0 finished: first at SparkUpperServiceImpl.java:231, took 0.320431 s
[INFO] [2018-10-29 22:46:51][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@20398b7c: startup date [Mon Oct 29 22:46:45 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 22:46:51][org.apache.spark.SparkContext]Invoking stop() from shutdown hook
[INFO] [2018-10-29 22:46:51][org.apache.spark.SparkContext]SparkContext already stopped.
[INFO] [2018-10-29 22:46:51][org.apache.spark.storage.DiskBlockManager]Shutdown hook called
[INFO] [2018-10-29 22:46:51][org.spark_project.jetty.server.AbstractConnector]Stopped Spark@1ceac56b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[INFO] [2018-10-29 22:46:51][org.apache.spark.ui.SparkUI]Stopped Spark web UI at http://192.168.68.1:4040
[INFO] [2018-10-29 22:46:51][org.apache.spark.util.ShutdownHookManager]Shutdown hook called
[INFO] [2018-10-29 22:46:51][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-58dd8618-6d3b-4ce7-ac44-b3498603f203
[INFO] [2018-10-29 22:46:51][org.apache.spark.MapOutputTrackerMasterEndpoint]MapOutputTrackerMasterEndpoint stopped!
[INFO] [2018-10-29 22:46:51][org.apache.spark.util.ShutdownHookManager]Deleting directory C:\Users\20474\AppData\Local\Temp\spark-58dd8618-6d3b-4ce7-ac44-b3498603f203\userFiles-b08de28e-07fe-497f-8d3b-53bd5d43d05b
[INFO] [2018-10-29 22:46:51][org.apache.spark.storage.memory.MemoryStore]MemoryStore cleared
[INFO] [2018-10-29 22:46:51][org.apache.spark.storage.BlockManager]BlockManager stopped
[INFO] [2018-10-29 22:46:51][org.apache.spark.storage.BlockManagerMaster]BlockManagerMaster stopped
[INFO] [2018-10-29 22:46:51][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint]OutputCommitCoordinator stopped!
[INFO] [2018-10-29 22:46:51][org.apache.spark.SparkContext]Successfully stopped SparkContext
[INFO] [2018-10-29 23:17:15][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-29 23:17:16][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@20398b7c: startup date [Mon Oct 29 23:17:16 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 23:17:16][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-29 23:17:16][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-29 23:17:16][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-29 23:17:16][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-29 23:17:16][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[ERROR] [2018-10-29 23:17:17][org.springframework.test.context.TestContextManager]Caught exception while allowing TestExecutionListener [org.springframework.test.context.support.DependencyInjectionTestExecutionListener@1efe439d] to prepare test instance [com.harleycorp.testmybatis.TestMyBatis@be68757]
java.lang.IllegalStateException: Failed to load ApplicationContext
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContext(CacheAwareContextLoaderDelegate.java:99)
	at org.springframework.test.context.DefaultTestContext.getApplicationContext(DefaultTestContext.java:101)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:109)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:75)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:319)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:212)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:232)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:89)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:175)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'testController': Injection of resource dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkUpperServiceImpl': Injection of resource dependencies failed; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [org.apache.spark.api.java.JavaSparkContext] found for dependency: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: {@javax.annotation.Resource(shareable=true, lookup=, name=, description=, authenticationType=CONTAINER, type=class java.lang.Object, mappedName=)}
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:307)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:700)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:121)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:100)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:250)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContextInternal(CacheAwareContextLoaderDelegate.java:64)
	at org.springframework.test.context.CacheAwareContextLoaderDelegate.loadContext(CacheAwareContextLoaderDelegate.java:91)
	... 25 more
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkUpperServiceImpl': Injection of resource dependencies failed; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [org.apache.spark.api.java.JavaSparkContext] found for dependency: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: {@javax.annotation.Resource(shareable=true, lookup=, name=, description=, authenticationType=CONTAINER, type=class java.lang.Object, mappedName=)}
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:307)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1014)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:957)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:855)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:441)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	... 41 more
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [org.apache.spark.api.java.JavaSparkContext] found for dependency: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: {@javax.annotation.Resource(shareable=true, lookup=, name=, description=, authenticationType=CONTAINER, type=class java.lang.Object, mappedName=)}
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoSuchBeanDefinitionException(DefaultListableBeanFactory.java:1100)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:960)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:855)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:441)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	... 57 more
[INFO] [2018-10-29 23:17:41][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-29 23:17:42][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@20398b7c: startup date [Mon Oct 29 23:17:42 CST 2018]; root of context hierarchy
[INFO] [2018-10-29 23:17:42][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-29 23:17:42][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-29 23:17:42][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-29 23:17:42][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-29 23:17:42][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-29 23:17:43][com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource]Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 3, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, dataSourceName -> 1hgeebl9y1hduluf123n6dj|3f4faf53, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> com.mysql.jdbc.Driver, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, identityToken -> 1hgeebl9y1hduluf123n6dj|3f4faf53, idleConnectionTestPeriod -> 0, initialPoolSize -> 1, jdbcUrl -> jdbc:mysql://192.168.68.244:3306/myjianshu, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 20, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 1, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, numThreadsAwaitingCheckoutDefaultUser -> 0, preferredTestQuery -> null, properties -> {user=******, password=******}, propertyCycle -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false ]
[INFO] [2018-10-29 23:17:43][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@20398b7c: startup date [Mon Oct 29 23:17:42 CST 2018]; root of context hierarchy
[INFO] [2018-10-30 00:01:41][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-30 00:01:42][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@5f9d02cb: startup date [Tue Oct 30 00:01:42 CST 2018]; root of context hierarchy
[INFO] [2018-10-30 00:01:42][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-30 00:01:42][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-30 00:01:42][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-30 00:01:42][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-30 00:01:42][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-30 00:01:43][com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource]Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 3, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, dataSourceName -> 1hgeebl9y1hff6w42djhnl|c430e6c, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> com.mysql.jdbc.Driver, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, identityToken -> 1hgeebl9y1hff6w42djhnl|c430e6c, idleConnectionTestPeriod -> 0, initialPoolSize -> 1, jdbcUrl -> jdbc:mysql://192.168.68.244:3306/myjianshu, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 20, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 1, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, numThreadsAwaitingCheckoutDefaultUser -> 0, preferredTestQuery -> null, properties -> {user=******, password=******}, propertyCycle -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false ]
[INFO] [2018-10-30 00:01:43][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@5f9d02cb: startup date [Tue Oct 30 00:01:42 CST 2018]; root of context hierarchy
[INFO] [2018-10-30 00:07:15][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-30 00:07:15][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@5f9d02cb: startup date [Tue Oct 30 00:07:15 CST 2018]; root of context hierarchy
[INFO] [2018-10-30 00:07:15][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-30 00:07:15][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-30 00:07:15][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-30 00:07:15][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-30 00:07:16][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-30 00:07:16][com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource]Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 3, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, dataSourceName -> 1hgeebl9y1hfmc87p7y43a|c430e6c, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> com.mysql.jdbc.Driver, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, identityToken -> 1hgeebl9y1hfmc87p7y43a|c430e6c, idleConnectionTestPeriod -> 0, initialPoolSize -> 1, jdbcUrl -> jdbc:mysql://192.168.68.244:3306/myjianshu, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 20, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 1, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, numThreadsAwaitingCheckoutDefaultUser -> 0, preferredTestQuery -> null, properties -> {user=******, password=******}, propertyCycle -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false ]
[INFO] [2018-10-30 00:07:17][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@5f9d02cb: startup date [Tue Oct 30 00:07:15 CST 2018]; root of context hierarchy
[INFO] [2018-10-30 00:09:13][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-30 00:09:14][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@5f9d02cb: startup date [Tue Oct 30 00:09:14 CST 2018]; root of context hierarchy
[INFO] [2018-10-30 00:09:14][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-30 00:09:14][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-30 00:09:14][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-30 00:09:14][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-30 00:09:14][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-30 00:09:15][com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource]Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 3, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, dataSourceName -> 1hgeebl9y1hfovpnunl0tk|c430e6c, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> com.mysql.jdbc.Driver, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, identityToken -> 1hgeebl9y1hfovpnunl0tk|c430e6c, idleConnectionTestPeriod -> 0, initialPoolSize -> 1, jdbcUrl -> jdbc:mysql://192.168.68.244:3306/myjianshu, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 20, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 1, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, numThreadsAwaitingCheckoutDefaultUser -> 0, preferredTestQuery -> null, properties -> {user=******, password=******}, propertyCycle -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false ]
[INFO] [2018-10-30 00:09:16][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@5f9d02cb: startup date [Tue Oct 30 00:09:14 CST 2018]; root of context hierarchy
[INFO] [2018-10-30 00:09:29][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-30 00:09:29][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@5f9d02cb: startup date [Tue Oct 30 00:09:29 CST 2018]; root of context hierarchy
[INFO] [2018-10-30 00:09:30][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-30 00:09:30][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-30 00:09:30][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-30 00:09:30][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-30 00:09:30][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-30 00:09:31][com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource]Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 3, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, dataSourceName -> 1hgeebl9y1hfp80dyt6i9v|c430e6c, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> com.mysql.jdbc.Driver, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, identityToken -> 1hgeebl9y1hfp80dyt6i9v|c430e6c, idleConnectionTestPeriod -> 0, initialPoolSize -> 1, jdbcUrl -> jdbc:mysql://192.168.68.244:3306/myjianshu, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 20, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 1, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, numThreadsAwaitingCheckoutDefaultUser -> 0, preferredTestQuery -> null, properties -> {user=******, password=******}, propertyCycle -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false ]
[INFO] [2018-10-30 00:09:31][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@5f9d02cb: startup date [Tue Oct 30 00:09:29 CST 2018]; root of context hierarchy
[INFO] [2018-10-30 00:29:03][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-30 00:29:04][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@5f9d02cb: startup date [Tue Oct 30 00:29:04 CST 2018]; root of context hierarchy
[INFO] [2018-10-30 00:29:04][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-30 00:29:04][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-30 00:29:04][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-30 00:29:04][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-30 00:29:04][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-30 00:29:05][com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource]Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 3, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, dataSourceName -> 1hgeebl9y1hgedze1ubmcxr|c430e6c, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> com.mysql.jdbc.Driver, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, identityToken -> 1hgeebl9y1hgedze1ubmcxr|c430e6c, idleConnectionTestPeriod -> 0, initialPoolSize -> 1, jdbcUrl -> jdbc:mysql://192.168.68.244:3306/myjianshu, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 20, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 1, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, numThreadsAwaitingCheckoutDefaultUser -> 0, preferredTestQuery -> null, properties -> {user=******, password=******}, propertyCycle -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false ]
[INFO] [2018-10-30 00:29:06][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@5f9d02cb: startup date [Tue Oct 30 00:29:04 CST 2018]; root of context hierarchy
[INFO] [2018-10-30 09:50:44][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-30 09:50:45][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@4c59ee42: startup date [Tue Oct 30 09:50:45 CST 2018]; root of context hierarchy
[INFO] [2018-10-30 09:50:45][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-30 09:50:45][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-30 09:50:45][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-30 09:50:46][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-30 09:50:46][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-30 09:50:47][org.apache.spark.SparkContext]Running Spark version 2.2.1
[WARN] [2018-10-30 09:50:57][org.apache.hadoop.util.NativeCodeLoader]Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR] [2018-10-30 09:50:57][org.apache.hadoop.util.Shell]Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2424)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2424)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2424)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2516)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:918)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:910)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:910)
	at com.harleycorp.service.impl.SparkUpperServiceImpl.getHourFreqByUserID(SparkUpperServiceImpl.java:243)
	at com.harleycorp.testmybatis.TestMyBatis.test1(TestMyBatis.java:40)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:74)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:83)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:72)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:232)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:89)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:175)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
[INFO] [2018-10-30 09:50:57][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@4c59ee42: startup date [Tue Oct 30 09:50:45 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 10:49:24][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-31 10:49:25][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@4c59ee42: startup date [Wed Oct 31 10:49:25 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 10:49:25][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-31 10:49:25][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-31 10:49:25][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-31 10:49:25][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-31 10:49:25][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[ERROR] [2018-10-31 10:49:26][org.springframework.test.context.TestContextManager]Caught exception while allowing TestExecutionListener [org.springframework.test.context.support.DependencyInjectionTestExecutionListener@2ce92fea] to prepare test instance [com.harleycorp.testmybatis.TestMyBatis@148c2af]
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'com.harleycorp.testmybatis.TestMyBatis': Injection of resource dependencies failed; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [com.harleycorp.service.RedisCRUD] found for dependency: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: {@javax.annotation.Resource(shareable=true, mappedName=, description=, name=, type=class java.lang.Object, authenticationType=CONTAINER, lookup=)}
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:307)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireBeanProperties(AbstractAutowireCapableBeanFactory.java:384)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:110)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:75)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:319)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:212)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:232)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:89)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:175)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [com.harleycorp.service.RedisCRUD] found for dependency: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: {@javax.annotation.Resource(shareable=true, mappedName=, description=, name=, type=class java.lang.Object, authenticationType=CONTAINER, lookup=)}
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoSuchBeanDefinitionException(DefaultListableBeanFactory.java:1100)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:960)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:855)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:441)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	... 26 more
[INFO] [2018-10-31 10:49:26][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@4c59ee42: startup date [Wed Oct 31 10:49:25 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 10:50:54][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-31 10:50:55][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@4c59ee42: startup date [Wed Oct 31 10:50:55 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 10:50:55][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-31 10:50:55][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-31 10:50:55][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-31 10:50:55][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-31 10:50:55][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[ERROR] [2018-10-31 10:50:56][org.springframework.test.context.TestContextManager]Caught exception while allowing TestExecutionListener [org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4d32397e] to prepare test instance [com.harleycorp.testmybatis.TestMyBatis@1c5ca6ca]
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'com.harleycorp.testmybatis.TestMyBatis': Injection of resource dependencies failed; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [com.harleycorp.service.RedisCRUD] found for dependency: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: {@javax.annotation.Resource(shareable=true, mappedName=, description=, name=, type=class java.lang.Object, authenticationType=CONTAINER, lookup=)}
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:307)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireBeanProperties(AbstractAutowireCapableBeanFactory.java:384)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:110)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:75)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:319)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:212)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:232)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:89)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:175)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [com.harleycorp.service.RedisCRUD] found for dependency: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: {@javax.annotation.Resource(shareable=true, mappedName=, description=, name=, type=class java.lang.Object, authenticationType=CONTAINER, lookup=)}
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoSuchBeanDefinitionException(DefaultListableBeanFactory.java:1100)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:960)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:855)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:441)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:419)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:544)
	at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:155)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessPropertyValues(CommonAnnotationBeanPostProcessor.java:304)
	... 26 more
[INFO] [2018-10-31 10:50:56][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@4c59ee42: startup date [Wed Oct 31 10:50:55 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 10:53:03][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-31 10:53:04][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@4c59ee42: startup date [Wed Oct 31 10:53:04 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 10:53:04][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-31 10:53:04][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-31 10:53:04][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-31 10:53:04][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-31 10:53:04][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-31 10:53:05][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@4c59ee42: startup date [Wed Oct 31 10:53:04 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 10:53:55][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-31 10:53:55][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@24295637: startup date [Wed Oct 31 10:53:55 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 10:53:55][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-31 10:53:55][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-31 10:53:55][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-31 10:53:56][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-31 10:53:56][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-31 10:53:57][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@24295637: startup date [Wed Oct 31 10:53:55 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 10:57:14][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-31 10:57:15][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@24295637: startup date [Wed Oct 31 10:57:15 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 10:57:15][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-31 10:57:15][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-31 10:57:15][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-31 10:57:15][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-31 10:57:15][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-31 10:57:16][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@24295637: startup date [Wed Oct 31 10:57:15 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 11:01:13][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-31 11:01:14][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@1ba5cfae: startup date [Wed Oct 31 11:01:14 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 11:01:14][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-31 11:01:14][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-31 11:01:14][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-31 11:01:14][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-31 11:01:14][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-31 11:02:06][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@1ba5cfae: startup date [Wed Oct 31 11:01:14 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 11:02:38][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-31 11:02:39][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@3541fcda: startup date [Wed Oct 31 11:02:39 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 11:02:39][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-31 11:02:39][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-31 11:02:39][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-31 11:02:39][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-31 11:02:39][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-31 11:03:47][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-31 11:03:47][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@24295637: startup date [Wed Oct 31 11:03:47 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 11:03:48][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-31 11:03:48][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-31 11:03:48][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-31 11:03:48][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-31 11:03:48][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-31 11:03:49][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@24295637: startup date [Wed Oct 31 11:03:47 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 11:06:36][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-31 11:06:37][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@24295637: startup date [Wed Oct 31 11:06:37 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 11:06:37][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-31 11:06:37][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-31 11:06:37][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-31 11:06:37][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-31 11:06:37][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-31 11:06:38][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@24295637: startup date [Wed Oct 31 11:06:37 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 11:10:03][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-31 11:10:03][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@4c59ee42: startup date [Wed Oct 31 11:10:03 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 11:10:03][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-31 11:10:03][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-31 11:10:03][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-31 11:10:03][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-31 11:10:04][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-31 11:10:05][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@4c59ee42: startup date [Wed Oct 31 11:10:03 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 11:10:11][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-31 11:10:11][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@794baafe: startup date [Wed Oct 31 11:10:11 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 11:10:11][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-31 11:10:11][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-31 11:10:12][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-31 11:10:12][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-31 11:10:12][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-31 11:27:21][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-10-31 11:27:21][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@6f2e5050: startup date [Wed Oct 31 11:27:21 CST 2018]; root of context hierarchy
[INFO] [2018-10-31 11:27:21][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-10-31 11:27:21][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-10-31 11:27:21][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-10-31 11:27:21][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-10-31 11:27:22][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-10-31 11:27:23][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@6f2e5050: startup date [Wed Oct 31 11:27:21 CST 2018]; root of context hierarchy
[INFO] [2018-11-01 15:25:38][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-11-01 15:25:39][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@6f2e5050: startup date [Thu Nov 01 15:25:39 CST 2018]; root of context hierarchy
[INFO] [2018-11-01 15:25:39][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-11-01 15:25:39][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-11-01 15:25:39][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-11-01 15:25:39][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-11-01 15:25:39][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-11-01 15:25:41][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@6f2e5050: startup date [Thu Nov 01 15:25:39 CST 2018]; root of context hierarchy
[INFO] [2018-11-01 15:33:15][org.springframework.beans.factory.xml.XmlBeanDefinitionReader]Loading XML bean definitions from class path resource [spring-mybatis.xml]
[INFO] [2018-11-01 15:33:15][org.springframework.context.support.GenericApplicationContext]Refreshing org.springframework.context.support.GenericApplicationContext@499aed36: startup date [Thu Nov 01 15:33:15 CST 2018]; root of context hierarchy
[INFO] [2018-11-01 15:33:15][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [jdbc.properties]
[INFO] [2018-11-01 15:33:15][org.springframework.beans.factory.config.PropertyPlaceholderConfigurer]Loading properties file from class path resource [spark.properties]
[INFO] [2018-11-01 15:33:15][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor]JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[INFO] [2018-11-01 15:33:15][com.mchange.v2.log.MLog]MLog clients using log4j logging.
[INFO] [2018-11-01 15:33:15][com.mchange.v2.c3p0.C3P0Registry]Initializing c3p0-0.9.1.2 [built 21-May-2007 15:04:56; debug? true; trace: 10]
[INFO] [2018-11-01 15:33:17][org.springframework.context.support.GenericApplicationContext]Closing org.springframework.context.support.GenericApplicationContext@499aed36: startup date [Thu Nov 01 15:33:15 CST 2018]; root of context hierarchy
